{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "411fb6fe",
   "metadata": {},
   "source": [
    "# Large model inference with DeepSpeed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37683c0d",
   "metadata": {},
   "source": [
    "## 1. Download trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28b6b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker \n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket() # Set a default S3 bucket\n",
    "\n",
    "account = sagemaker_session.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "\n",
    "\n",
    "model_s3_uri= f\"s3://{bucket}/fine-tune-GPTJ/checkpoint/checkpoint-120/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d6ea896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-10 20:32:17        961 config.json\n",
      "2023-02-10 20:32:17        141 generation_config.json\n",
      "2023-02-10 20:32:17         14 latest\n",
      "2023-02-10 20:32:17     456318 merges.txt\n",
      "2023-02-10 20:41:12 12216972905 pytorch_model.bin\n",
      "2023-02-10 20:32:17      14583 rng_state_0.pth\n",
      "2023-02-10 20:32:17      14583 rng_state_1.pth\n",
      "2023-02-10 20:32:17      14583 rng_state_2.pth\n",
      "2023-02-10 20:32:17      14583 rng_state_3.pth\n",
      "2023-02-10 20:32:17        470 special_tokens_map.json\n",
      "2023-02-10 20:32:17        748 tokenizer_config.json\n",
      "2023-02-10 20:32:17       1606 trainer_state.json\n",
      "2023-02-10 20:32:17       4795 training_args.bin\n",
      "2023-02-10 20:32:17     999186 vocab.json\n",
      "2023-02-10 20:32:17      18857 zero_to_fp32.py\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $model_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fab4f29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 rm $model_s3_uri/global_step120/ --recursive "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb96aa69",
   "metadata": {},
   "source": [
    "# 2. Prepare docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1939c8",
   "metadata": {},
   "source": [
    "We have a `build.sh` bash script which performs the following steps:\n",
    "\n",
    "* Makes `serve` executable and builds our docker image\n",
    "* Optionally, runs the container for local testing\n",
    "\n",
    "Run with local testing using the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9d26fa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/GPTJ/amazon-sagemaker-gptj/Deploy_GPTJ_DeepSpeed\n",
      "Sending build context to Docker daemon  27.14kB\n",
      "Step 1/13 : FROM pytorch/pytorch:1.8.1-cuda11.1-cudnn8-devel\n",
      " ---> 7afd9b52a068\n",
      "Step 2/13 : LABEL com.amazon.image.authors.email=\"sage-learner@amazon.com\"\n",
      " ---> Using cache\n",
      " ---> f67c72f9e1a9\n",
      "Step 3/13 : LABEL com.amazon.image.authors.name=\"Amazon AI\"\n",
      " ---> Using cache\n",
      " ---> d42e1cf112da\n",
      "Step 4/13 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 11349f25d74a\n",
      "Step 5/13 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> 69242df3ee5f\n",
      "Step 6/13 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 1b113a70efdd\n",
      "Step 7/13 : ARG DEBIAN_FRONTEND=noninteractive\n",
      " ---> Using cache\n",
      " ---> 027f75146b58\n",
      "Step 8/13 : ENV TZ=Etc/UTC\n",
      " ---> Using cache\n",
      " ---> 3799d6c545c5\n",
      "Step 9/13 : RUN apt-key del 7fa2af80     && rm /etc/apt/sources.list.d/nvidia-ml.list /etc/apt/sources.list.d/cuda.list     && apt-get -y update && apt-get install -y --no-install-recommends         wget     && wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-keyring_1.0-1_all.deb     && dpkg -i cuda-keyring_1.0-1_all.deb     && apt-get -y update && apt-get install -y --no-install-recommends         python3-pip         python3-setuptools         nginx         ca-certificates     && apt-get -y autoremove     && apt-get clean autoclean     && rm -fr /var/lib/apt/lists/{apt,dpkg,cache,log} /tmp/* /var/tmp/*\n",
      " ---> Using cache\n",
      " ---> 7511b9507099\n",
      "Step 10/13 : RUN ln -s /usr/bin/python3 /usr/bin/python\n",
      " ---> Using cache\n",
      " ---> 219af5856e4b\n",
      "Step 11/13 : RUN pip --version     && pip --no-cache-dir install         transformers==4.15         deepspeed==0.5.10         flask==2.1.2         gunicorn==20.1.0         awscli\n",
      " ---> Using cache\n",
      " ---> 61df5a36c941\n",
      "Step 12/13 : COPY ./src /opt/program\n",
      " ---> Using cache\n",
      " ---> 357d07134c92\n",
      "Step 13/13 : WORKDIR /opt/program\n",
      " ---> Using cache\n",
      " ---> 822ae02b5d7a\n",
      "Successfully built 822ae02b5d7a\n",
      "Successfully tagged gptj-inference-endpoint:latest\n",
      "d69099badda8a8f1a2d80b3f1d0f29453806cbe5e2a9bfe6586636e0c29abcde\n",
      "REPOSITORY                                                             TAG                           IMAGE ID       CREATED         SIZE\n",
      "gptj-inference-endpoint                                                latest                        822ae02b5d7a   8 seconds ago   16.8GB\n",
      "171503325295.dkr.ecr.us-east-1.amazonaws.com/gptj-inference-endpoint   latest                        d2a5e70a127d   3 hours ago     16.7GB\n",
      "<none>                                                                 <none>                        a59346497518   3 hours ago     16.7GB\n",
      "<none>                                                                 <none>                        6688c7614247   3 hours ago     16.7GB\n",
      "<none>                                                                 <none>                        207d638c4d17   3 hours ago     16.7GB\n",
      "<none>                                                                 <none>                        ed7a0eb57999   3 hours ago     16.7GB\n",
      "<none>                                                                 <none>                        95393daba20d   3 hours ago     11.1GB\n",
      "<none>                                                                 <none>                        86b82e6653c3   3 hours ago     11.1GB\n",
      "<none>                                                                 <none>                        eb1d6ec3b148   4 hours ago     11GB\n",
      "<none>                                                                 <none>                        d08c737ee994   4 hours ago     11GB\n",
      "<none>                                                                 <none>                        adfc626c5264   4 hours ago     10.7GB\n",
      "<none>                                                                 <none>                        e3c6a8401267   4 hours ago     8.45GB\n",
      "<none>                                                                 <none>                        8bef37008f21   4 hours ago     16.7GB\n",
      "<none>                                                                 <none>                        ac73b2618128   4 hours ago     16.7GB\n",
      "<none>                                                                 <none>                        0c17e511eb69   4 hours ago     16.7GB\n",
      "<none>                                                                 <none>                        7bbbf1c57783   4 hours ago     16.7GB\n",
      "<none>                                                                 <none>                        508b1a5f3605   18 hours ago    4.85GB\n",
      "<none>                                                                 <none>                        cff8e3f86ae1   18 hours ago    16.7GB\n",
      "<none>                                                                 <none>                        43559737ea65   19 hours ago    16.8GB\n",
      "<none>                                                                 <none>                        ffb7b075356c   19 hours ago    16.8GB\n",
      "<none>                                                                 <none>                        cc8faa6a0b2b   19 hours ago    16.8GB\n",
      "<none>                                                                 <none>                        afb2664131ef   19 hours ago    16.8GB\n",
      "<none>                                                                 <none>                        22147bdf2e47   19 hours ago    16.8GB\n",
      "<none>                                                                 <none>                        1c6a0e8dc2e5   19 hours ago    16.7GB\n",
      "<none>                                                                 <none>                        ecf3afac0d0d   19 hours ago    16.7GB\n",
      "<none>                                                                 <none>                        cfbad82707ae   19 hours ago    16.7GB\n",
      "<none>                                                                 <none>                        109ddc5739a0   19 hours ago    16.7GB\n",
      "<none>                                                                 <none>                        97226a10ae6d   19 hours ago    16.7GB\n",
      "<none>                                                                 <none>                        807c36780876   21 hours ago    16.7GB\n",
      "nvidia/cuda                                                            11.7.1-devel-ubuntu20.04      c4f8d3c928f4   8 weeks ago     4.85GB\n",
      "pytorch/pytorch                                                        1.8.1-cuda11.1-cudnn8-devel   7afd9b52a068   22 months ago   16.5GB\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "cd ../Deploy_GPTJ_DeepSpeed/\n",
    "./build.sh gptj-inference-endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a28a36",
   "metadata": {},
   "source": [
    "# 3. Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "010bb958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "The push refers to repository [171503325295.dkr.ecr.us-east-1.amazonaws.com/gptj-inference-endpoint]\n",
      "6fd3f091def6: Preparing\n",
      "450d5b5f658a: Preparing\n",
      "bef584e29ea6: Preparing\n",
      "6b23b4f5045b: Preparing\n",
      "ecc6bb7de61b: Preparing\n",
      "1aa7263f678e: Preparing\n",
      "6ee3d43a62a1: Preparing\n",
      "ffe4fc4a44ce: Preparing\n",
      "9f70bc5acecf: Preparing\n",
      "63c72fb01f89: Preparing\n",
      "ad5b6813b3ac: Preparing\n",
      "7a2f30aca740: Preparing\n",
      "cd37cd672bd2: Preparing\n",
      "fe6d8881187d: Preparing\n",
      "23135df75b44: Preparing\n",
      "b43408d5f11b: Preparing\n",
      "7a2f30aca740: Waiting\n",
      "63c72fb01f89: Waiting\n",
      "ad5b6813b3ac: Waiting\n",
      "6ee3d43a62a1: Waiting\n",
      "cd37cd672bd2: Waiting\n",
      "1aa7263f678e: Waiting\n",
      "23135df75b44: Waiting\n",
      "b43408d5f11b: Waiting\n",
      "fe6d8881187d: Waiting\n",
      "ffe4fc4a44ce: Waiting\n",
      "9f70bc5acecf: Waiting\n",
      "bef584e29ea6: Layer already exists\n",
      "ecc6bb7de61b: Layer already exists\n",
      "6b23b4f5045b: Layer already exists\n",
      "1aa7263f678e: Layer already exists\n",
      "6ee3d43a62a1: Layer already exists\n",
      "ffe4fc4a44ce: Layer already exists\n",
      "9f70bc5acecf: Layer already exists\n",
      "63c72fb01f89: Layer already exists\n",
      "ad5b6813b3ac: Layer already exists\n",
      "7a2f30aca740: Layer already exists\n",
      "cd37cd672bd2: Layer already exists\n",
      "fe6d8881187d: Layer already exists\n",
      "23135df75b44: Layer already exists\n",
      "b43408d5f11b: Layer already exists\n",
      "6fd3f091def6: Pushed\n",
      "450d5b5f658a: Pushed\n",
      "latest: digest: sha256:c9cd245e9546368f38434ac743e75ec380d7da8af18b65904cf3b4d5e206d361 size: 3687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "cd ../Deploy_GPTJ_DeepSpeed/\n",
    "chmod +x push_to_ecr.sh\n",
    "./push_to_ecr.sh gptj-inference-endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445fea66",
   "metadata": {},
   "source": [
    "First, this script will push your image to ECR. For reference later, note the address of the repository that the container is pushed to. It should appear below the line `Login Succeeded` in the output from the call to `push_to_ecr.sh`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986f7fd1",
   "metadata": {},
   "source": [
    "# 4. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850ca85f",
   "metadata": {},
   "source": [
    "Now, you can deploy your endpoint as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d77302",
   "metadata": {},
   "source": [
    "### 4.1 Initialize configuration variables\n",
    "\n",
    "If you run into the error that endpoint already exists on a rerun, please change the model_name and endpoint_name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bf66430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import RealTimePredictor\n",
    "import time \n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# Specify path to gptj-inference-endpoint image in ECR\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/gptj-inference-endpoint:latest'.format(account, region)\n",
    "\n",
    "# Specify sagemaker model_name\n",
    "sm_model_name = \"gptj-completion-gpu-test\"\n",
    "\n",
    "# Specify endpoint_name\n",
    "endpoint_name = \"gptj-completion-gpu-test\"\n",
    "\n",
    "# Specify instance_type\n",
    "instance_type = 'ml.g4dn.2xlarge'\n",
    "\n",
    "# Specify initial_instance_count\n",
    "initial_instance_count = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7a1226",
   "metadata": {},
   "source": [
    "### 4.2 Initialize endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca4caeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: gptj-completion-gpu-test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---"
     ]
    }
   ],
   "source": [
    "sm_model = Model(\n",
    "                        image_uri = image,\n",
    "                        role = role,\n",
    "                         env={\"S3_MODEL_LOCATION\":model_s3_uri},\n",
    "                        predictor_cls=RealTimePredictor,\n",
    "                        name = sm_model_name)\n",
    "\n",
    "predictor = sm_model.deploy(\n",
    "        instance_type=instance_type,\n",
    "        initial_instance_count=1,\n",
    "        endpoint_name = endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542bef7d",
   "metadata": {},
   "source": [
    "### 4.3 Query model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdc508d",
   "metadata": {},
   "source": [
    "To query your endpoint, you can use the code below. Also, remember that you can pass any parameters accepted by the HuggingFace `\"text-generation\"` pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b0dbe2",
   "metadata": {},
   "source": [
    "#### Initialize asynchronous "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14a4822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json \n",
    "\n",
    "# Get the boto3 session and sagemaker client, as well as the current execution role\n",
    "sess = boto3.Session()\n",
    "\n",
    "# Specify your AWS Region\n",
    "aws_region=sess.region_name\n",
    "\n",
    "\n",
    "# Create a low-level client representing Amazon SageMaker Runtime\n",
    "sagemaker_runtime = boto3.client(\"sagemaker-runtime\", region_name=aws_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d57c98b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.05 ms, sys: 0 ns, total: 4.05 ms\n",
      "Wall time: 534 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "text = \"love: \"\n",
    "\n",
    "parameters = {\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_new_tokens\":200,\n",
    "    \"min_tokens\": 100,\n",
    "    \"repetition_penalty\": 1.1,\n",
    "    \"top_p\": 500,\n",
    "    }\n",
    "\n",
    "data = {\n",
    "    \"inputs\": {\n",
    "        \"text_inputs\": text,\n",
    "        \"parameters\": parameters\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "body = json.dumps(data)\n",
    "\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint( \n",
    "        EndpointName=endpoint_name, \n",
    "        Body = body, \n",
    "        ContentType = 'application/json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0271567f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 ms, sys: 373 µs, total: 11.4 ms\n",
      "Wall time: 834 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "body = json.dumps(data)\n",
    "\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint( \n",
    "        EndpointName=endpoint_name, \n",
    "        Body = body, \n",
    "        ContentType = 'application/json'\n",
    ")\n",
    "\n",
    "result = json.loads(response['Body'].read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e503eb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': [{'generated_text': 'love:  The most powerful weapon anyone can have is a loving and forgiving heart.'}],\n",
       " 'status': 200}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
