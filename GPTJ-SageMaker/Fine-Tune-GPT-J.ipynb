{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune GPTJ on SageMaker Training with Deepspeed\n",
    "\n",
    "In this notebook we will finetune GPTJ on the processed [quotes dataset](https://www.kaggle.com/datasets/akmittal/quotes-dataset). This notebook/repo makes use of [this GitHub repo](https://github.com/Xirider/finetune-gpt2xl) where the Dockerfile has been adpated to be compliant with SageMaker. \n",
    "\n",
    "The dataset is in the format we wish to make inference with:\n",
    "\n",
    "`<Catagory>: <AIGeneratedQuote>`+\n",
    "\n",
    "Example: \n",
    "*We want to give GTJ a catagory and it must generate a quote*\n",
    "\n",
    "`love: <AIGeneratedQuote>`\n",
    "\n",
    "Take a look at the quote dataset we will be using in this notebook. \n",
    "1. [train.csv](https://raw.githubusercontent.com/marckarp/amazon-sagemaker-fine-tune-gptj/main/Finetune_GPTNEO_GPTJ6B/quotes_dataset/train.csv)\n",
    "2. [validation.csv](https://raw.githubusercontent.com/marckarp/amazon-sagemaker-fine-tune-gptj/main/Finetune_GPTNEO_GPTJ6B/quotes_dataset/validation.csv)\n",
    "\n",
    "If you wish to make use of your own dataset feel free to create a train and validation dataset with your own data to accomplish the task you are setting out to achieve. \n",
    "\n",
    "For more details on preparing a dataset please see [this link](https://github.com/mallorbc/Finetune_GPTNEO_GPTJ6B/tree/main/finetuning_repo#preparing-a-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (2.128.0)\n",
      "Collecting sagemaker\n",
      "  Using cached sagemaker-2.132.0.tar.gz (668 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (1.26.46)\n",
      "Collecting boto3\n",
      "  Using cached boto3-1.26.67-py3-none-any.whl (132 kB)\n",
      "Requirement already satisfied: attrs<23,>=20.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (22.1.0)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (1.22.4)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (3.20.2)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (4.13.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (1.4.4)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sagemaker) (0.7.5)\n",
      "Collecting botocore<1.30.0,>=1.29.67\n",
      "  Using cached botocore-1.29.67-py3-none-any.whl (10.4 MB)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from botocore<1.30.0,>=1.29.67->boto3) (1.26.8)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from botocore<1.30.0,>=1.29.67->boto3) (2.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging>=20.0->sagemaker) (3.0.9)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas->sagemaker) (2022.5)\n",
      "Requirement already satisfied: dill>=0.3.6 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.132.0-py2.py3-none-any.whl size=905449 sha256=bc553449c2403ff315c2a11f173aad2549b0ad504c2f65de13ffba3bd34c6bb3\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/b5/e9/08/e877c056814c01a15dc1b3de802cc212a254a50500fdc8ef66\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: botocore, boto3, sagemaker\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.29.46\n",
      "    Uninstalling botocore-1.29.46:\n",
      "      Successfully uninstalled botocore-1.29.46\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.26.46\n",
      "    Uninstalling boto3-1.26.46:\n",
      "      Successfully uninstalled boto3-1.26.46\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.128.0\n",
      "    Uninstalling sagemaker-2.128.0:\n",
      "      Successfully uninstalled sagemaker-2.128.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.27.46 requires botocore==1.29.46, but you have botocore 1.29.67 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.26.67 botocore-1.29.67 sagemaker-2.132.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker boto3 --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build & Push the container for SageMaker Training\n",
    "\n",
    "In order to fine tune GPTJ we will have to make use of a docker container with Deepspeed installed. \n",
    "The Dockerfile is adapted from this repo [here](https://github.com/mallorbc/Finetune_GPTNEO_GPTJ6B/blob/main/Dockerfile). It has been adapted to be SageMaker compatible. \n",
    "\n",
    "Below we will define the deepspeed CLI command that will be run within our SageMaker Training Job. It has been paramterized using Enviroment variables so that we can have the ability to tune/customize the parameters when we kick of a SageMaker Training Job. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../Finetune_GPTNEO_GPTJ6B/train\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../Finetune_GPTNEO_GPTJ6B/train\n",
    "#!/bin/bash\n",
    "\n",
    "df -h\n",
    "cd finetuning_repo\n",
    "\n",
    "deepspeed --num_gpus=$num_gpus run_clm.py --deepspeed $deepspeed --model_name_or_path EleutherAI/gpt-j-6B --train_file /opt/ml/input/data/train/train.csv --validation_file /opt/ml/input/data/validation/validation.csv --do_train --do_eval --fp16 --overwrite_cache --evaluation_strategy=$evaluation_strategy --output_dir $output_dir --num_train_epochs $num_train_epochs  --eval_steps $eval_steps --gradient_accumulation_steps $gradient_accumulation_steps --per_device_train_batch_size $per_device_train_batch_size --use_fast_tokenizer $use_fast_tokenizer --learning_rate $learning_rate --warmup_steps $warmup_steps --save_total_limit $save_total_limit --save_steps $save_steps --save_strategy $save_strategy --tokenizer_name $tokenizer_name --load_best_model_at_end=$load_best_model_at_end --block_size=$block_size --weight_decay=$weight_decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the train file we created above as executable. Once we have all our files ready we can build and push our image to ECR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh \n",
    "\n",
    "cd ../Finetune_GPTNEO_GPTJ6B\n",
    "chmod +x train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  65.28MB\n",
      "Step 1/20 : FROM nvidia/cuda:11.7.1-devel-ubuntu20.04\n",
      " ---> c4f8d3c928f4\n",
      "Step 2/20 : ARG DEBIAN_FRONTEND=noninteractive\n",
      " ---> Using cache\n",
      " ---> 88306a3cab77\n",
      "Step 3/20 : SHELL [ \"/bin/bash\",\"-c\" ]\n",
      " ---> Using cache\n",
      " ---> 823a73990dba\n",
      "Step 4/20 : ENV NVIDIA_VISIBLE_DEVICES all\n",
      " ---> Using cache\n",
      " ---> 72cf8e27e0ab\n",
      "Step 5/20 : ENV NVIDIA_DRIVER_CAPABILITIES compute,video,utility\n",
      " ---> Using cache\n",
      " ---> 9490e3109300\n",
      "Step 6/20 : RUN apt update -y && apt upgrade -y\n",
      " ---> Using cache\n",
      " ---> 969f84ed6f63\n",
      "Step 7/20 : RUN apt install wget -y && apt install git -y && apt install libaio-dev -y && apt install libaio1 -y\n",
      " ---> Using cache\n",
      " ---> f42adf5187a7\n",
      "Step 8/20 : RUN apt install python3.9 -y && apt install python3-pip -y && apt install python-is-python3 -y\n",
      " ---> Using cache\n",
      " ---> 896beed91d20\n",
      "Step 9/20 : RUN pip install torch torchvision torchaudio\n",
      " ---> Using cache\n",
      " ---> e18593d3bfb5\n",
      "Step 10/20 : RUN pip install datasets && pip install transformers && pip install accelerate\n",
      " ---> Using cache\n",
      " ---> c2f2f2d6a697\n",
      "Step 11/20 : RUN pip install triton==1.0.0\n",
      " ---> Using cache\n",
      " ---> 1feecbbf2754\n",
      "Step 12/20 : RUN DS_BUILD_OPS=1 pip install git+https://github.com/microsoft/DeepSpeed.git@v0.7.7\n",
      " ---> Using cache\n",
      " ---> db887d76312f\n",
      "Step 13/20 : RUN pip install git+https://github.com/mallorbc/DeepSpeed-MII.git\n",
      " ---> Using cache\n",
      " ---> 779cfdeaeab2\n",
      "Step 14/20 : RUN pip install wandb\n",
      " ---> Using cache\n",
      " ---> 5de0e2078a57\n",
      "Step 15/20 : ENV WANDB_DISABLED=true\n",
      " ---> Using cache\n",
      " ---> 0af10f425e04\n",
      "Step 16/20 : ENV TRANSFORMERS_CACHE=/opt/ml/model\n",
      " ---> Using cache\n",
      " ---> 089f6641676d\n",
      "Step 17/20 : ENV HF_DATASETS_CACHE=/opt/ml/model\n",
      " ---> Using cache\n",
      " ---> 969b33f87b7e\n",
      "Step 18/20 : COPY . /workspace\n",
      " ---> Using cache\n",
      " ---> 7e1d74fceb6c\n",
      "Step 19/20 : WORKDIR /workspace\n",
      " ---> Using cache\n",
      " ---> 1e4dd871067e\n",
      "Step 20/20 : ENTRYPOINT [\"./train\"]\n",
      " ---> Using cache\n",
      " ---> 2db19bc9fbc4\n",
      "Successfully built 2db19bc9fbc4\n",
      "Successfully tagged gptj-finetune:latest\n",
      "The push refers to repository [171503325295.dkr.ecr.us-east-1.amazonaws.com/gptj-finetune]\n",
      "6e69eebd066b: Preparing\n",
      "fc73b03206b6: Preparing\n",
      "eb4d2133084d: Preparing\n",
      "476ef8434420: Preparing\n",
      "ef0ddefd4679: Preparing\n",
      "0d284709ef4f: Preparing\n",
      "3d1ddcace106: Preparing\n",
      "c0510c3a6a95: Preparing\n",
      "cccb9f22be9f: Preparing\n",
      "13597fc5b8d1: Preparing\n",
      "822919f77330: Preparing\n",
      "a2654928891a: Preparing\n",
      "cdedc6c127e1: Preparing\n",
      "ac85f70f8859: Preparing\n",
      "590f3ac20d28: Preparing\n",
      "c0510c3a6a95: Waiting\n",
      "c263f12cd4e6: Preparing\n",
      "99832d04a153: Preparing\n",
      "cccb9f22be9f: Waiting\n",
      "a5981ed7a378: Preparing\n",
      "250519a2f830: Preparing\n",
      "6cadbde53f94: Preparing\n",
      "0002c93bdb37: Preparing\n",
      "13597fc5b8d1: Waiting\n",
      "ac85f70f8859: Waiting\n",
      "590f3ac20d28: Waiting\n",
      "822919f77330: Waiting\n",
      "a2654928891a: Waiting\n",
      "cdedc6c127e1: Waiting\n",
      "c263f12cd4e6: Waiting\n",
      "99832d04a153: Waiting\n",
      "6cadbde53f94: Waiting\n",
      "a5981ed7a378: Waiting\n",
      "250519a2f830: Waiting\n",
      "0002c93bdb37: Waiting\n",
      "0d284709ef4f: Waiting\n",
      "3d1ddcace106: Waiting\n",
      "476ef8434420: Layer already exists\n",
      "fc73b03206b6: Layer already exists\n",
      "eb4d2133084d: Layer already exists\n",
      "6e69eebd066b: Layer already exists\n",
      "ef0ddefd4679: Layer already exists\n",
      "0d284709ef4f: Layer already exists\n",
      "c0510c3a6a95: Layer already exists\n",
      "3d1ddcace106: Layer already exists\n",
      "cccb9f22be9f: Layer already exists\n",
      "13597fc5b8d1: Layer already exists\n",
      "822919f77330: Layer already exists\n",
      "cdedc6c127e1: Layer already exists\n",
      "a2654928891a: Layer already exists\n",
      "590f3ac20d28: Layer already exists\n",
      "ac85f70f8859: Layer already exists\n",
      "c263f12cd4e6: Layer already exists\n",
      "99832d04a153: Layer already exists\n",
      "a5981ed7a378: Layer already exists\n",
      "250519a2f830: Layer already exists\n",
      "6cadbde53f94: Layer already exists\n",
      "0002c93bdb37: Layer already exists\n",
      "latest: digest: sha256:6e7dff8e40cf00d1cffe08bcb8a8381e49bb6b5f918c5541e864d5372111b6a4 size: 4752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "cd ../Finetune_GPTNEO_GPTJ6B\n",
    "./build_push_image.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Training\n",
    "\n",
    "Once the image has been pushed to ECR we can then kick off the Training Job but first we need to create a SageMaker Estimator object. That contains the information required to start a Training Job. \n",
    "\n",
    "There is a number of paramaters you can tune. Depending on the number of GPUs avaialble you set `num_gpus`. The deepspeed configratuon file is also parameterized. \n",
    "\n",
    "There are three options to choose from:\n",
    "1. ds_config_stage1.json\n",
    "2. ds_config_stage2.json\n",
    "3. ds_config_stage3.json\n",
    "\n",
    "https://github.com/mallorbc/Finetune_GPTNEO_GPTJ6B/tree/main/finetuning_repo#deepspeed\n",
    "\n",
    "\n",
    "Training and finetuning a model is an experimental science. You may want to tune different learning rates, weight decay, etc.\n",
    "\n",
    "The Training Job has also been configured to emit metrics such as `eval_loss`. The regex for the metrics that the container emits is specified in `metric_definitions`.  You can use these metrics to decide if you wish to stop the Training Job if you do not see an improvement in the loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker \n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "from sagemaker import local\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "#local_sagemaker_session = local.LocalSession()\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "account = sagemaker_session.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/gptj-finetune:latest'.format(account, region)\n",
    "\n",
    "bucket = sagemaker_session.default_bucket() # Set a default S3 bucket\n",
    "prefix = 'DEMO-fine-tune-GPTJ'\n",
    "\n",
    "\n",
    "sm_model = sagemaker.estimator.Estimator(\n",
    "image_uri=image,\n",
    "role=role,\n",
    "instance_count = 1,\n",
    "#instance_type='local_gpu', \n",
    "#sagemaker_session=local_sagemaker_session,\n",
    "sagemaker_session= sagemaker_session,\n",
    "#instance_type = 'ml.g5.48xlarge',\n",
    "instance_type=\"ml.g5.12xlarge\",\n",
    "environment = {\n",
    "    \"num_gpus\": \"4\",\n",
    "    \"deepspeed\": \"ds_config_stage3.json\",\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"output_dir\": \"/opt/ml/model/finetune\",\n",
    "    \"num_train_epochs\": \"12\",\n",
    "    \"eval_steps\": \"20\",\n",
    "    \"gradient_accumulation_steps\": \"1\",\n",
    "    \"per_device_train_batch_size\": \"4\",\n",
    "    \"use_fast_tokenizer\": \"False\",\n",
    "    \"learning_rate\": \"5e-06\",\n",
    "    \"warmup_steps\": \"10\",\n",
    "    \"save_total_limit\": \"1\",\n",
    "    \"save_steps\": \"20\",\n",
    "    \"save_strategy\": \"steps\",\n",
    "    \"tokenizer_name\": \"gpt2\",\n",
    "    \"load_best_model_at_end\": \"True\",\n",
    "    \"block_size\": \"2048\",\n",
    "    \"weight_decay\": \"0.1\"\n",
    "},\n",
    "    \n",
    "output_path=f\"s3://{bucket}/fine-tune-GPTJ/output/\",\n",
    "\n",
    "metric_definitions=[\n",
    "    {'Name': 'eval:loss', 'Regex': \"'eval_loss': ([0-9]+\\.[0-9]+)\"},\n",
    "    {'Name': 'eval:runtime', 'Regex': \"'eval_runtime': ([0-9]+\\.[0-9]+)\"},\n",
    "    {'Name': 'eval:samples_per_second', 'Regex': \"'eval_samples_per_second': ([0-9]+\\.[0-9]+)\"},\n",
    "    {'Name': 'eval:eval_steps_per_second', 'Regex': \"'eval_steps_per_second': ([0-9]+\\.[0-9]+)\"},\n",
    "]\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case we will be using the processed quotes dataset to finetune GPTJ and as such we upload the train and validation set to S3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../Finetune_GPTNEO_GPTJ6B/quotes_dataset/train.csv to s3://sagemaker-us-east-1-171503325295/fine-tune-GPTJ/datasets/train/train.csv\n",
      "upload: ../Finetune_GPTNEO_GPTJ6B/quotes_dataset/validation.csv to s3://sagemaker-us-east-1-171503325295/fine-tune-GPTJ/datasets/validation/validation.csv\n"
     ]
    }
   ],
   "source": [
    "train_s3=f\"s3://{bucket}/fine-tune-GPTJ/datasets/train/train.csv\"\n",
    "val_s3=f\"s3://{bucket}/fine-tune-GPTJ/datasets/validation/validation.csv\"\n",
    "\n",
    "\n",
    "!aws s3 cp ../Finetune_GPTNEO_GPTJ6B/quotes_dataset/train.csv $train_s3\n",
    "!aws s3 cp ../Finetune_GPTNEO_GPTJ6B/quotes_dataset/validation.csv $val_s3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The container we bult expects two datasets, a train and validation dataset. Here set the training input channels \"train\" and \"validation\" which each point to their respective S3 locations for SageMaker to make use of during Training. SageMaker handles downloading the datasets to the container from S3 on our behalf. \n",
    "\n",
    "Finally, we kick off the job with the `.fit()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: gptj-finetune-2023-02-09-06-35-31-223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-09 06:35:31 Starting - Starting the training job...\n",
      "2023-02-09 06:35:59 Starting - Preparing the instances for training......\n",
      "2023-02-09 06:37:00 Downloading - Downloading input data...\n",
      "2023-02-09 06:37:15 Training - Downloading the training image.....................\n",
      "2023-02-09 06:40:41 Training - Training image download completed. Training in progress...\u001b[34mFilesystem      Size  Used Avail Use% Mounted on\u001b[0m\n",
      "\u001b[34moverlay          65G   35G   31G  54% /\u001b[0m\n",
      "\u001b[34mtmpfs            64M     0   64M   0% /dev\u001b[0m\n",
      "\u001b[34mtmpfs            94G     0   94G   0% /sys/fs/cgroup\u001b[0m\n",
      "\u001b[34m/dev/nvme0n1p1   65G   35G   31G  54% /usr/local/nvidia\u001b[0m\n",
      "\u001b[34m/dev/nvme2n1    3.5T  8.5M  3.3T   1% /tmp\u001b[0m\n",
      "\u001b[34mshm              93G     0   93G   0% /dev/shm\u001b[0m\n",
      "\u001b[34mtmpfs            94G   12K   94G   1% /proc/driver/nvidia\u001b[0m\n",
      "\u001b[34mtmpfs            94G  4.0K   94G   1% /etc/nvidia/nvidia-application-profiles-rc.d\u001b[0m\n",
      "\u001b[34mtmpfs            94G  1.4M   94G   1% /run/nvidia-persistenced/socket\u001b[0m\n",
      "\u001b[34mdevtmpfs         94G     0   94G   0% /dev/nvidia0\u001b[0m\n",
      "\u001b[34mtmpfs            94G     0   94G   0% /proc/acpi\u001b[0m\n",
      "\u001b[34mtmpfs            94G     0   94G   0% /sys/firmware\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:41:12,247] [WARNING] [runner.py:179:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:41:12,273] [INFO] [runner.py:508:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 --master_addr=127.0.0.1 --master_port=29500 run_clm.py --deepspeed ds_config_stage3.json --model_name_or_path EleutherAI/gpt-j-6B --train_file /opt/ml/input/data/train/train.csv --validation_file /opt/ml/input/data/validation/validation.csv --do_train --do_eval --fp16 --overwrite_cache --evaluation_strategy=steps --output_dir /opt/ml/model/finetune --num_train_epochs 12 --eval_steps 20 --gradient_accumulation_steps 1 --per_device_train_batch_size 4 --use_fast_tokenizer False --learning_rate 5e-06 --warmup_steps 10 --save_total_limit 1 --save_steps 20 --save_strategy steps --tokenizer_name gpt2 --load_best_model_at_end=True --block_size=2048 --weight_decay=0.1\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:41:13,868] [INFO] [launch.py:135:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.13.4-1+cuda11.7\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:41:13,869] [INFO] [launch.py:135:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.13.4-1\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:41:13,869] [INFO] [launch.py:135:main] 0 NCCL_VERSION=2.13.4-1\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:41:13,869] [INFO] [launch.py:135:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:41:13,869] [INFO] [launch.py:135:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.13.4-1+cuda11.7\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:41:13,869] [INFO] [launch.py:135:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:41:13,869] [INFO] [launch.py:135:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.13.4-1\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:41:13,869] [INFO] [launch.py:142:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3]}\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:41:13,869] [INFO] [launch.py:148:main] nnodes=1, num_local_procs=4, node_rank=0\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:41:13,869] [INFO] [launch.py:161:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:41:13,869] [INFO] [launch.py:162:main] dist_world_size=4\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:41:13,869] [INFO] [launch.py:164:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:41:17,507] [INFO] [comm.py:654:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\u001b[0m\n",
      "\u001b[34mUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\u001b[0m\n",
      "\u001b[34mUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\u001b[0m\n",
      "\u001b[34mUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\u001b[0m\n",
      "\u001b[34m02/09/2023 06:41:17 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\u001b[0m\n",
      "\u001b[34mUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\u001b[0m\n",
      "\u001b[34m02/09/2023 06:41:17 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\u001b[0m\n",
      "\u001b[34m_n_gpu=1,\u001b[0m\n",
      "\u001b[34madafactor=False,\u001b[0m\n",
      "\u001b[34madam_beta1=0.9,\u001b[0m\n",
      "\u001b[34madam_beta2=0.999,\u001b[0m\n",
      "\u001b[34madam_epsilon=1e-08,\u001b[0m\n",
      "\u001b[34mauto_find_batch_size=False,\u001b[0m\n",
      "\u001b[34mbf16=False,\u001b[0m\n",
      "\u001b[34mbf16_full_eval=False,\u001b[0m\n",
      "\u001b[34mdata_seed=None,\u001b[0m\n",
      "\u001b[34mdataloader_drop_last=False,\u001b[0m\n",
      "\u001b[34mdataloader_num_workers=0,\u001b[0m\n",
      "\u001b[34mdataloader_pin_memory=True,\u001b[0m\n",
      "\u001b[34mddp_bucket_cap_mb=None,\u001b[0m\n",
      "\u001b[34mddp_find_unused_parameters=None,\u001b[0m\n",
      "\u001b[34mddp_timeout=1800,\u001b[0m\n",
      "\u001b[34mdebug=[],\u001b[0m\n",
      "\u001b[34mdeepspeed=ds_config_stage3.json,\u001b[0m\n",
      "\u001b[34mdisable_tqdm=False,\u001b[0m\n",
      "\u001b[34mdo_eval=True,\u001b[0m\n",
      "\u001b[34mdo_predict=False,\u001b[0m\n",
      "\u001b[34mdo_train=True,\u001b[0m\n",
      "\u001b[34meval_accumulation_steps=None,\u001b[0m\n",
      "\u001b[34meval_delay=0,\u001b[0m\n",
      "\u001b[34meval_steps=20,\u001b[0m\n",
      "\u001b[34mevaluation_strategy=steps,\u001b[0m\n",
      "\u001b[34mfp16=True,\u001b[0m\n",
      "\u001b[34mfp16_backend=auto,\u001b[0m\n",
      "\u001b[34mfp16_full_eval=False,\u001b[0m\n",
      "\u001b[34mfp16_opt_level=O1,\u001b[0m\n",
      "\u001b[34mfsdp=[],\u001b[0m\n",
      "\u001b[34mfsdp_min_num_params=0,\u001b[0m\n",
      "\u001b[34mfsdp_transformer_layer_cls_to_wrap=None,\u001b[0m\n",
      "\u001b[34mfull_determinism=False,\u001b[0m\n",
      "\u001b[34mgradient_accumulation_steps=1,\u001b[0m\n",
      "\u001b[34mgradient_checkpointing=False,\u001b[0m\n",
      "\u001b[34mgreater_is_better=False,\u001b[0m\n",
      "\u001b[34mgroup_by_length=False,\u001b[0m\n",
      "\u001b[34mhalf_precision_backend=auto,\u001b[0m\n",
      "\u001b[34mhub_model_id=None,\u001b[0m\n",
      "\u001b[34mhub_private_repo=False,\u001b[0m\n",
      "\u001b[34mhub_strategy=every_save,\u001b[0m\n",
      "\u001b[34mhub_token=<HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mignore_data_skip=False,\u001b[0m\n",
      "\u001b[34minclude_inputs_for_metrics=False,\u001b[0m\n",
      "\u001b[34mjit_mode_eval=False,\u001b[0m\n",
      "\u001b[34mlabel_names=None,\u001b[0m\n",
      "\u001b[34mlabel_smoothing_factor=0.0,\u001b[0m\n",
      "\u001b[34mlearning_rate=5e-06,\u001b[0m\n",
      "\u001b[34mlength_column_name=length,\u001b[0m\n",
      "\u001b[34mload_best_model_at_end=True,\u001b[0m\n",
      "\u001b[34mlocal_rank=0,\u001b[0m\n",
      "\u001b[34mlog_level=passive,\u001b[0m\n",
      "\u001b[34mlog_level_replica=passive,\u001b[0m\n",
      "\u001b[34mlog_on_each_node=True,\u001b[0m\n",
      "\u001b[34mlogging_dir=/opt/ml/model/finetune/runs/Feb09_06-41-17_ip-10-2-218-202.ec2.internal,\u001b[0m\n",
      "\u001b[34mlogging_first_step=False,\u001b[0m\n",
      "\u001b[34mlogging_nan_inf_filter=True,\u001b[0m\n",
      "\u001b[34mlogging_steps=500,\u001b[0m\n",
      "\u001b[34mlogging_strategy=steps,\u001b[0m\n",
      "\u001b[34mlr_scheduler_type=linear,\u001b[0m\n",
      "\u001b[34mmax_grad_norm=1.0,\u001b[0m\n",
      "\u001b[34mmax_steps=-1,\u001b[0m\n",
      "\u001b[34mmetric_for_best_model=loss,\u001b[0m\n",
      "\u001b[34mmp_parameters=,\u001b[0m\n",
      "\u001b[34mno_cuda=False,\u001b[0m\n",
      "\u001b[34mnum_train_epochs=12.0,\u001b[0m\n",
      "\u001b[34moptim=adamw_hf,\u001b[0m\n",
      "\u001b[34moptim_args=None,\u001b[0m\n",
      "\u001b[34moutput_dir=/opt/ml/model/finetune,\u001b[0m\n",
      "\u001b[34moverwrite_output_dir=False,\u001b[0m\n",
      "\u001b[34mpast_index=-1,\u001b[0m\n",
      "\u001b[34mper_device_eval_batch_size=8,\u001b[0m\n",
      "\u001b[34mper_device_train_batch_size=4,\u001b[0m\n",
      "\u001b[34mprediction_loss_only=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub_model_id=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_organization=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mray_scope=last,\u001b[0m\n",
      "\u001b[34mremove_unused_columns=True,\u001b[0m\n",
      "\u001b[34mreport_to=[],\u001b[0m\n",
      "\u001b[34mresume_from_checkpoint=None,\u001b[0m\n",
      "\u001b[34mrun_name=/opt/ml/model/finetune,\u001b[0m\n",
      "\u001b[34msave_on_each_node=False,\u001b[0m\n",
      "\u001b[34msave_steps=20,\u001b[0m\n",
      "\u001b[34msave_strategy=steps,\u001b[0m\n",
      "\u001b[34msave_total_limit=1,\u001b[0m\n",
      "\u001b[34mseed=42,\u001b[0m\n",
      "\u001b[34msharded_ddp=[],\u001b[0m\n",
      "\u001b[34mskip_memory_metrics=True,\u001b[0m\n",
      "\u001b[34mtf32=None,\u001b[0m\n",
      "\u001b[34mtorch_compile=False,\u001b[0m\n",
      "\u001b[34mtorch_compile_backend=None,\u001b[0m\n",
      "\u001b[34mtorch_compile_mode=None,\u001b[0m\n",
      "\u001b[34mtorchdynamo=None,\u001b[0m\n",
      "\u001b[34mtpu_metrics_debug=False,\u001b[0m\n",
      "\u001b[34mtpu_num_cores=None,\u001b[0m\n",
      "\u001b[34muse_ipex=False,\u001b[0m\n",
      "\u001b[34muse_legacy_prediction_loop=False,\u001b[0m\n",
      "\u001b[34muse_mps_device=False,\u001b[0m\n",
      "\u001b[34mwarmup_ratio=0.0,\u001b[0m\n",
      "\u001b[34mwarmup_steps=10,\u001b[0m\n",
      "\u001b[34mweight_decay=0.1,\u001b[0m\n",
      "\u001b[34mxpu_backend=None,\u001b[0m\n",
      "\u001b[34m)\u001b[0m\n",
      "\u001b[34m02/09/2023 06:41:17 - WARNING - __main__ -   Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True\u001b[0m\n",
      "\u001b[34m02/09/2023 06:41:17 - WARNING - __main__ -   Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True\u001b[0m\n",
      "\u001b[34m02/09/2023 06:41:17 - WARNING - __main__ -   Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True\u001b[0m\n",
      "\u001b[34m02/09/2023 06:41:17 - WARNING - datasets.builder -   Using custom data configuration default-edad65e7a1bba695\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset csv/default to /opt/ml/model/csv/default-edad65e7a1bba695/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\u001b[0m\n",
      "\u001b[34m#015Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]#015Downloading data files: 100%|██████████| 2/2 [00:00<00:00, 15252.01it/s]\u001b[0m\n",
      "\u001b[34m02/09/2023 06:41:17 - WARNING - datasets.builder -   Using custom data configuration default-edad65e7a1bba695\u001b[0m\n",
      "\u001b[34m#015Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]#015Extracting data files: 100%|██████████| 2/2 [00:00<00:00, 2377.05it/s]\u001b[0m\n",
      "\u001b[34m02/09/2023 06:41:17 - WARNING - datasets.builder -   Using custom data configuration default-edad65e7a1bba695\u001b[0m\n",
      "\u001b[34m#015Generating train split: 0 examples [00:00, ? examples/s]/usr/local/lib/python3.8/dist-packages/datasets/download/streaming_download_manager.py:776: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\u001b[0m\n",
      "\u001b[34m02/09/2023 06:41:17 - WARNING - datasets.builder -   Using custom data configuration default-edad65e7a1bba695\u001b[0m\n",
      "\u001b[34m#015                                                        #015#015Generating validation split: 0 examples [00:00, ? examples/s]/usr/local/lib/python3.8/dist-packages/datasets/download/streaming_download_manager.py:776: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\u001b[0m\n",
      "\u001b[34mDataset csv downloaded and prepared to /opt/ml/model/csv/default-edad65e7a1bba695/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34m#015                                                             #015#015  0%|          | 0/2 [00:00<?, ?it/s]#015100%|██████████| 2/2 [00:00<00:00, 1049.23it/s]\u001b[0m\n",
      "\u001b[34m02/09/2023 06:41:17 - WARNING - datasets.builder -   Found cached dataset csv (/opt/ml/model/csv/default-edad65e7a1bba695/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/2 [00:00<?, ?it/s]#015100%|██████████| 2/2 [00:00<00:00, 958.04it/s]\u001b[0m\n",
      "\u001b[34m02/09/2023 06:41:17 - WARNING - datasets.builder -   Found cached dataset csv (/opt/ml/model/csv/default-edad65e7a1bba695/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\u001b[0m\n",
      "\u001b[34m02/09/2023 06:41:17 - WARNING - datasets.builder -   Found cached dataset csv (/opt/ml/model/csv/default-edad65e7a1bba695/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/2 [00:00<?, ?it/s]#015  0%|          | 0/2 [00:00<?, ?it/s]#015100%|██████████| 2/2 [00:00<00:00, 973.04it/s]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 2/2 [00:00<00:00, 947.12it/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)lve/main/config.json:   0%|          | 0.00/930 [00:00<?, ?B/s]#015Downloading (…)lve/main/config.json: 100%|██████████| 930/930 [00:00<00:00, 267kB/s]\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:660] 2023-02-09 06:41:18,033 >> loading configuration file config.json from cache at /opt/ml/model/models--EleutherAI--gpt-j-6B/snapshots/6e35e2148e92edf096e94d39ac2b98ad59e25975/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:712] 2023-02-09 06:41:18,034 >> Model config GPTJConfig {\n",
      "  \"_name_or_path\": \"EleutherAI/gpt-j-6B\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPTJForCausalLM\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.0,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gptj\",\n",
      "  \"n_embd\": 4096,\n",
      "  \"n_head\": 16,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 28,\n",
      "  \"n_positions\": 2048,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rotary\": true,\n",
      "  \"rotary_dim\": 64,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50,\n",
      "      \"temperature\": 1.0\n",
      "    }\n",
      "  },\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"GPT2Tokenizer\",\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50400\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m#015Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]#015Downloading (…)lve/main/config.json: 100%|██████████| 665/665 [00:00<00:00, 258kB/s]\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_auto.py:458] 2023-02-09 06:41:18,054 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:660] 2023-02-09 06:41:18,072 >> loading configuration file config.json from cache at /opt/ml/model/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:712] 2023-02-09 06:41:18,072 >> Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m#015Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]#015Downloading (…)olve/main/vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 78.7MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]#015Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 68.7MB/s]\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-02-09 06:41:18,230 >> loading file vocab.json from cache at /opt/ml/model/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/vocab.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-02-09 06:41:18,230 >> loading file merges.txt from cache at /opt/ml/model/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/merges.txt\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-02-09 06:41:18,230 >> loading file added_tokens.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-02-09 06:41:18,230 >> loading file special_tokens_map.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-02-09 06:41:18,230 >> loading file tokenizer_config.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:660] 2023-02-09 06:41:18,231 >> loading configuration file config.json from cache at /opt/ml/model/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:712] 2023-02-09 06:41:18,231 >> Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m02/09/2023 06:41:18 - INFO - __main__ -   Setting `block_size` to 2048\u001b[0m\n",
      "\u001b[34m#015Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/24.2G [00:00<?, ?B/s]#015Downloading (…)\"pytorch_model.bin\";:   0%|          | 41.9M/24.2G [00:00<01:01, 390MB/s]#015Downloading (…)\"pytorch_model.bin\";:   0%|          | 94.4M/24.2G [00:00<00:52, 460MB/s]#015Downloading (…)\"pytorch_model.bin\";:   1%|          | 147M/24.2G [00:00<00:49, 482MB/s] #015Downloading (…)\"pytorch_model.bin\";:   1%|          | 199M/24.2G [00:00<00:48, 493MB/s]#015Downloading (…)\"pytorch_model.bin\";:   1%|          | 252M/24.2G [00:00<00:48, 499MB/s]#015Downloading (…)\"pytorch_model.bin\";:   1%|▏         | 304M/24.2G [00:00<00:47, 502MB/s]#015Downloading (…)\"pytorch_model.bin\";:   1%|▏         | 357M/24.2G [00:00<00:47, 504MB/s]#015Downloading (…)\"pytorch_model.bin\";:   2%|▏         | 409M/24.2G [00:00<00:47, 505MB/s]#015Downloading (…)\"pytorch_model.bin\";:   2%|▏         | 461M/24.2G [00:00<00:46, 506MB/s]#015Downloading (…)\"pytorch_model.bin\";:   2%|▏         | 514M/24.2G [00:01<00:46, 507MB/s]#015Downloading (…)\"pytorch_model.bin\";:   2%|▏         | 566M/24.2G [00:01<00:46, 506MB/s]#015Downloading (…)\"pytorch_model.bin\";:   3%|▎         | 619M/24.2G [00:01<00:46, 508MB/s]#015Downloading (…)\"pytorch_model.bin\";:   3%|▎         | 671M/24.2G [00:01<00:52, 450MB/s]#015Downloading (…)\"pytorch_model.bin\";:   3%|▎         | 724M/24.2G [00:01<00:50, 463MB/s]#015Downloading (…)\"pytorch_model.bin\";:   3%|▎         | 776M/24.2G [00:01<00:49, 476MB/s]#015Downloading (…)\"pytorch_model.bin\";:   3%|▎         | 828M/24.2G [00:01<00:48, 482MB/s]#015Downloading (…)\"pytorch_model.bin\";:   4%|▎         | 881M/24.2G [00:01<00:47, 490MB/s]#015Downloading (…)\"pytorch_model.bin\";:   4%|▍         | 933M/24.2G [00:01<00:46, 496MB/s]#015Downloading (…)\"pytorch_model.bin\";:   4%|▍         | 986M/24.2G [00:02<00:46, 500MB/s]#015Downloading (…)\"pytorch_model.bin\";:   4%|▍         | 1.04G/24.2G [00:02<00:46, 503MB/s]#015Downloading (…)\"pytorch_model.bin\";:   5%|▍         | 1.09G/24.2G [00:02<00:45, 506MB/s]#015Downloading (…)\"pytorch_model.bin\";:   5%|▍         | 1.14G/24.2G [00:02<00:45, 508MB/s]#015Downloading (…)\"pytorch_model.bin\";:   5%|▍         | 1.20G/24.2G [00:02<00:45, 509MB/s]#015Downloading (…)\"pytorch_model.bin\";:   5%|▌         | 1.25G/24.2G [00:02<00:45, 508MB/s]#015Downloading (…)\"pytorch_model.bin\";:   5%|▌         | 1.30G/24.2G [00:02<00:45, 508MB/s]#015Downloading (…)\"pytorch_model.bin\";:   6%|▌         | 1.35G/24.2G [00:02<00:44, 509MB/s]#015Downloading (…)\"pytorch_model.bin\";:   6%|▌         | 1.41G/24.2G [00:02<00:44, 508MB/s]#015Downloading (…)\"pytorch_model.bin\";:   6%|▌         | 1.46G/24.2G [00:02<00:44, 508MB/s]#015Downloading (…)\"pytorch_model.bin\";:   6%|▌         | 1.51G/24.2G [00:03<00:45, 496MB/s]#015Downloading (…)\"pytorch_model.bin\";:   6%|▋         | 1.56G/24.2G [00:03<00:47, 475MB/s]#015Downloading (…)\"pytorch_model.bin\";:   7%|▋         | 1.61G/24.2G [00:03<00:46, 481MB/s]#015Downloading (…)\"pytorch_model.bin\";:   7%|▋         | 1.67G/24.2G [00:03<00:45, 490MB/s]#015Downloading (…)\"pytorch_model.bin\";:   7%|▋         | 1.72G/24.2G [00:03<00:46, 483MB/s]#015Downloading (…)\"pytorch_model.bin\";:   7%|▋         | 1.77G/24.2G [00:03<00:45, 491MB/s]#015Downloading (…)\"pytorch_model.bin\";:   8%|▊         | 1.82G/24.2G [00:03<00:45, 487MB/s]#015Downloading (…)\"pytorch_model.bin\";:   8%|▊         | 1.88G/24.2G [00:03<00:47, 473MB/s]#015Downloading (…)\"pytorch_model.bin\";:   8%|▊         | 1.93G/24.2G [00:03<00:49, 448MB/s]#015Downloading (…)\"pytorch_model.bin\";:   8%|▊         | 1.98G/24.2G [00:04<00:51, 430MB/s]#015Downloading (…)\"pytorch_model.bin\";:   8%|▊         | 2.03G/24.2G [00:04<00:50, 437MB/s]#015Downloading (…)\"pytorch_model.bin\";:   9%|▊         | 2.09G/24.2G [00:04<00:50, 436MB/s]#015Downloading (…)\"pytorch_model.bin\";:   9%|▉         | 2.14G/24.2G [00:04<00:49, 450MB/s]#015Downloading (…)\"pytorch_model.bin\";:   9%|▉         | 2.19G/24.2G [00:04<00:48, 456MB/s]#015Downloading (…)\"pytorch_model.bin\";:   9%|▉         | 2.24G/24.2G [00:04<00:46, 471MB/s]#015Downloading (…)\"pytorch_model.bin\";:   9%|▉         | 2.30G/24.2G [00:04<00:45, 483MB/s]#015Downloading (…)\"pytorch_model.bin\";:  10%|▉         | 2.35G/24.2G [00:04<00:44, 491MB/s]#015Downloading (…)\"pytorch_model.bin\";:  10%|▉         | 2.40G/24.2G [00:04<00:43, 496MB/s]#015Downloading (…)\"pytorch_model.bin\";:  10%|█         | 2.45G/24.2G [00:05<00:43, 500MB/s]#015Downloading (…)\"pytorch_model.bin\";:  10%|█         | 2.51G/24.2G [00:05<00:43, 503MB/s]#015Downloading (…)\"pytorch_model.bin\";:  11%|█         | 2.56G/24.2G [00:05<00:43, 503MB/s]#015Downloading (…)\"pytorch_model.bin\";:  11%|█         | 2.61G/24.2G [00:05<00:42, 506MB/s]#015Downloading (…)\"pytorch_model.bin\";:  11%|█         | 2.66G/24.2G [00:05<00:42, 508MB/s]#015Downloading (…)\"pytorch_model.bin\";:  11%|█         | 2.72G/24.2G [00:05<00:42, 509MB/s]#015Downloading (…)\"pytorch_model.bin\";:  11%|█▏        | 2.77G/24.2G [00:05<00:42, 510MB/s]#015Downloading (…)\"pytorch_model.bin\";:  12%|█▏        | 2.82G/24.2G [00:05<00:41, 510MB/s]#015Downloading (…)\"pytorch_model.bin\";:  12%|█▏        | 2.87G/24.2G [00:05<00:41, 511MB/s]#015Downloading (…)\"pytorch_model.bin\";:  12%|█▏        | 2.93G/24.2G [00:06<00:44, 480MB/s]#015Downloading (…)\"pytorch_model.bin\";:  12%|█▏        | 2.98G/24.2G [00:06<00:45, 472MB/s]#015Downloading (…)\"pytorch_model.bin\";:  13%|█▎        | 3.03G/24.2G [00:06<00:43, 483MB/s]#015Downloading (…)\"pytorch_model.bin\";:  13%|█▎        | 3.08G/24.2G [00:06<00:43, 485MB/s]#015Downloading (…)\"pytorch_model.bin\";:  13%|█▎        | 3.14G/24.2G [00:06<00:42, 491MB/s]#015Downloading (…)\"pytorch_model.bin\";:  13%|█▎        | 3.19G/24.2G [00:06<00:42, 497MB/s]#015Downloading (…)\"pytorch_model.bin\";:  13%|█▎        | 3.24G/24.2G [00:06<00:41, 502MB/s]#015Downloading (…)\"pytorch_model.bin\";:  14%|█▎        | 3.29G/24.2G [00:06<00:41, 503MB/s]#015Downloading (…)\"pytorch_model.bin\";:  14%|█▍        | 3.34G/24.2G [00:06<00:41, 505MB/s]#015Downloading (…)\"pytorch_model.bin\";:  14%|█▍        | 3.40G/24.2G [00:06<00:41, 501MB/s]#015Downloading (…)\"pytorch_model.bin\";:  14%|█▍        | 3.45G/24.2G [00:07<00:41, 501MB/s]#015Downloading (…)\"pytorch_model.bin\";:  14%|█▍        | 3.50G/24.2G [00:07<00:41, 501MB/s]#015Downloading (…)\"pytorch_model.bin\";:  15%|█▍        | 3.55G/24.2G [00:07<00:41, 501MB/s]#015Downloading (…)\"pytorch_model.bin\";:  15%|█▍        | 3.61G/24.2G [00:07<00:40, 503MB/s]#015Downloading (…)\"pytorch_model.bin\";:  15%|█▌        | 3.66G/24.2G [00:07<00:40, 506MB/s]#015Downloading (…)\"pytorch_model.bin\";:  15%|█▌        | 3.71G/24.2G [00:07<00:40, 507MB/s]#015Downloading (…)\"pytorch_model.bin\";:  16%|█▌        | 3.76G/24.2G [00:07<00:40, 508MB/s]#015Downloading (…)\"pytorch_model.bin\";:  16%|█▌        | 3.82G/24.2G [00:07<00:40, 509MB/s]#015Downloading (…)\"pytorch_model.bin\";:  16%|█▌        | 3.87G/24.2G [00:07<00:39, 510MB/s]#015Downloading (…)\"pytorch_model.bin\";:  16%|█▌        | 3.92G/24.2G [00:07<00:39, 511MB/s]#015Downloading (…)\"pytorch_model.bin\";:  16%|█▋        | 3.97G/24.2G [00:08<00:39, 511MB/s]#015Downloading (…)\"pytorch_model.bin\";:  17%|█▋        | 4.03G/24.2G [00:08<00:39, 512MB/s]#015Downloading (…)\"pytorch_model.bin\";:  17%|█▋        | 4.08G/24.2G [00:08<00:39, 511MB/s]#015Downloading (…)\"pytorch_model.bin\";:  17%|█▋        | 4.13G/24.2G [00:08<00:39, 508MB/s]#015Downloading (…)\"pytorch_model.bin\";:  17%|█▋        | 4.18G/24.2G [00:08<00:39, 509MB/s]#015Downloading (…)\"pytorch_model.bin\";:  17%|█▋        | 4.24G/24.2G [00:08<00:39, 511MB/s]#015Downloading (…)\"pytorch_model.bin\";:  18%|█▊        | 4.29G/24.2G [00:08<00:38, 511MB/s]#015Downloading (…)\"pytorch_model.bin\";:  18%|█▊        | 4.34G/24.2G [00:08<00:38, 510MB/s]#015Downloading (…)\"pytorch_model.bin\";:  18%|█▊        | 4.39G/24.2G [00:08<00:38, 511MB/s]#015Downloading (…)\"pytorch_model.bin\";:  18%|█▊        | 4.45G/24.2G [00:09<00:38, 509MB/s]#015Downloading (…)\"pytorch_model.bin\";:  19%|█▊        | 4.50G/24.2G [00:09<00:38, 509MB/s]#015Downloading (…)\"pytorch_model.bin\";:  19%|█▉        | 4.55G/24.2G [00:09<00:38, 510MB/s]#015Downloading (…)\"pytorch_model.bin\";:  19%|█▉        | 4.60G/24.2G [00:09<00:38, 508MB/s]#015Downloading (…)\"pytorch_model.bin\";:  19%|█▉        | 4.66G/24.2G [00:09<00:38, 506MB/s]#015Downloading (…)\"pytorch_model.bin\";:  19%|█▉        | 4.71G/24.2G [00:09<00:38, 508MB/s]#015Downloading (…)\"pytorch_model.bin\";:  20%|█▉        | 4.76G/24.2G [00:09<00:38, 504MB/s]#015Downloading (…)\"pytorch_model.bin\";:  20%|█▉        | 4.81G/24.2G [00:09<00:38, 500MB/s]#015Downloading (…)\"pytorch_model.bin\";:  20%|██        | 4.87G/24.2G [00:09<00:38, 499MB/s]#015Downloading (…)\"pytorch_model.bin\";:  20%|██        | 4.92G/24.2G [00:09<00:38, 498MB/s]#015Downloading (…)\"pytorch_model.bin\";:  21%|██        | 4.97G/24.2G [00:10<00:38, 498MB/s]#015Downloading (…)\"pytorch_model.bin\";:  21%|██        | 5.02G/24.2G [00:10<00:38, 496MB/s]#015Downloading (…)\"pytorch_model.bin\";:  21%|██        | 5.08G/24.2G [00:10<00:50, 376MB/s]#015Downloading (…)\"pytorch_model.bin\";:  21%|██        | 5.13G/24.2G [00:10<00:47, 402MB/s]#015Downloading (…)\"pytorch_model.bin\";:  21%|██▏       | 5.18G/24.2G [00:10<00:44, 423MB/s]#015Downloading (…)\"pytorch_model.bin\";:  22%|██▏       | 5.23G/24.2G [00:10<00:42, 442MB/s]#015Downloading (…)\"pytorch_model.bin\";:  22%|██▏       | 5.28G/24.2G [00:10<00:41, 457MB/s]#015Downloading (…)\"pytorch_model.bin\";:  22%|██▏       | 5.34G/24.2G [00:10<00:40, 468MB/s]#015Downloading (…)\"pytorch_model.bin\";:  22%|██▏       | 5.39G/24.2G [00:11<00:39, 472MB/s]#015Downloading (…)\"pytorch_model.bin\";:  22%|██▏       | 5.44G/24.2G [00:11<00:39, 480MB/s]#015Downloading (…)\"pytorch_model.bin\";:  23%|██▎       | 5.49G/24.2G [00:11<00:38, 482MB/s]#015Downloading (…)\"pytorch_model.bin\";:  23%|██▎       | 5.55G/24.2G [00:11<00:38, 485MB/s]#015Downloading (…)\"pytorch_model.bin\";:  23%|██▎       | 5.60G/24.2G [00:11<00:38, 488MB/s]#015Downloading (…)\"pytorch_model.bin\";:  23%|██▎       | 5.65G/24.2G [00:11<00:38, 486MB/s]#015Downloading (…)\"pytorch_model.bin\";:  24%|██▎       | 5.70G/24.2G [00:11<00:37, 489MB/s]#015Downloading (…)\"pytorch_model.bin\";:  24%|██▍       | 5.76G/24.2G [00:11<00:38, 480MB/s]#015Downloading (…)\"pytorch_model.bin\";:  24%|██▍       | 5.81G/24.2G [00:11<00:38, 483MB/s]#015Downloading (…)\"pytorch_model.bin\";:  24%|██▍       | 5.86G/24.2G [00:11<00:37, 488MB/s]#015Downloading (…)\"pytorch_model.bin\";:  24%|██▍       | 5.91G/24.2G [00:12<00:37, 492MB/s]#015Downloading (…)\"pytorch_model.bin\";:  25%|██▍       | 5.97G/24.2G [00:12<00:36, 494MB/s]#015Downloading (…)\"pytorch_model.bin\";:  25%|██▍       | 6.02G/24.2G [00:12<00:36, 497MB/s]#015Downloading (…)\"pytorch_model.bin\";:  25%|██▌       | 6.07G/24.2G [00:12<00:36, 498MB/s]#015Downloading (…)\"pytorch_model.bin\";:  25%|██▌       | 6.12G/24.2G [00:12<00:36, 497MB/s]#015Downloading (…)\"pytorch_model.bin\";:  26%|██▌       | 6.18G/24.2G [00:12<00:36, 499MB/s]#015Downloading (…)\"pytorch_model.bin\";:  26%|██▌       | 6.23G/24.2G [00:12<00:35, 500MB/s]#015Downloading (…)\"pytorch_model.bin\";:  26%|██▌       | 6.28G/24.2G [00:12<00:35, 504MB/s]#015Downloading (…)\"pytorch_model.bin\";:  26%|██▌       | 6.33G/24.2G [00:12<00:35, 506MB/s]#015Downloading (…)\"pytorch_model.bin\";:  26%|██▋       | 6.39G/24.2G [00:13<00:35, 507MB/s]#015Downloading (…)\"pytorch_model.bin\";:  27%|██▋       | 6.44G/24.2G [00:13<00:34, 509MB/s]#015Downloading (…)\"pytorch_model.bin\";:  27%|██▋       | 6.49G/24.2G [00:13<00:34, 510MB/s]#015Downloading (…)\"pytorch_model.bin\";:  27%|██▋       | 6.54G/24.2G [00:13<00:34, 508MB/s]#015Downloading (…)\"pytorch_model.bin\";:  27%|██▋       | 6.60G/24.2G [00:13<00:34, 507MB/s]#015Downloading (…)\"pytorch_model.bin\";:  27%|██▋       | 6.65G/24.2G [00:13<00:34, 507MB/s]#015Downloading (…)\"pytorch_model.bin\";:  28%|██▊       | 6.70G/24.2G [00:13<00:34, 508MB/s]#015Downloading (…)\"pytorch_model.bin\";:  28%|██▊       | 6.75G/24.2G [00:13<00:34, 509MB/s]#015Downloading (…)\"pytorch_model.bin\";:  28%|██▊       | 6.81G/24.2G [00:13<00:34, 510MB/s]#015Downloading (…)\"pytorch_model.bin\";:  28%|██▊       | 6.86G/24.2G [00:13<00:33, 511MB/s]#015Downloading (…)\"pytorch_model.bin\";:  29%|██▊       | 6.91G/24.2G [00:14<00:33, 511MB/s]#015Downloading (…)\"pytorch_model.bin\";:  29%|██▉       | 6.96G/24.2G [00:14<00:33, 510MB/s]#015Downloading (…)\"pytorch_model.bin\";:  29%|██▉       | 7.01G/24.2G [00:14<00:33, 510MB/s]#015Downloading (…)\"pytorch_model.bin\";:  29%|██▉       | 7.07G/24.2G [00:14<00:34, 504MB/s]#015Downloading (…)\"pytorch_model.bin\";:  29%|██▉       | 7.12G/24.2G [00:14<00:34, 501MB/s]#015Downloading (…)\"pytorch_model.bin\";:  30%|██▉       | 7.17G/24.2G [00:14<00:34, 491MB/s]#015Downloading (…)\"pytorch_model.bin\";:  30%|██▉       | 7.22G/24.2G [00:14<00:34, 494MB/s]#015Downloading (…)\"pytorch_model.bin\";:  30%|███       | 7.28G/24.2G [00:14<00:34, 493MB/s]#015Downloading (…)\"pytorch_model.bin\";:  30%|███       | 7.33G/24.2G [00:14<00:34, 491MB/s]#015Downloading (…)\"pytorch_model.bin\";:  30%|███       | 7.38G/24.2G [00:15<00:34, 493MB/s]#015Downloading (…)\"pytorch_model.bin\";:  31%|███       | 7.43G/24.2G [00:15<00:34, 489MB/s]#015Downloading (…)\"pytorch_model.bin\";:  31%|███       | 7.49G/24.2G [00:15<00:33, 493MB/s]#015Downloading (…)\"pytorch_model.bin\";:  31%|███       | 7.54G/24.2G [00:15<00:34, 487MB/s]#015Downloading (…)\"pytorch_model.bin\";:  31%|███▏      | 7.59G/24.2G [00:15<00:34, 475MB/s]#015Downloading (…)\"pytorch_model.bin\";:  32%|███▏      | 7.64G/24.2G [00:15<00:36, 460MB/s]#015Downloading (…)\"pytorch_model.bin\";:  32%|███▏      | 7.70G/24.2G [00:15<00:36, 457MB/s]#015Downloading (…)\"pytorch_model.bin\";:  32%|███▏      | 7.75G/24.2G [00:15<00:36, 447MB/s]#015Downloading (…)\"pytorch_model.bin\";:  32%|███▏      | 7.80G/24.2G [00:15<00:36, 446MB/s]#015Downloading (…)\"pytorch_model.bin\";:  32%|███▏      | 7.85G/24.2G [00:16<00:36, 444MB/s]#015Downloading (…)\"pytorch_model.bin\";:  33%|███▎      | 7.91G/24.2G [00:16<00:37, 438MB/s]#015Downloading (…)\"pytorch_model.bin\";:  33%|███▎      | 7.96G/24.2G [00:16<00:36, 440MB/s]#015Downloading (…)\"pytorch_model.bin\";:  33%|███▎      | 8.01G/24.2G [00:16<00:36, 442MB/s]#015Downloading (…)\"pytorch_model.bin\";:  33%|███▎      | 8.06G/24.2G [00:16<00:36, 444MB/s]#015Downloading (…)\"pytorch_model.bin\";:  34%|███▎      | 8.12G/24.2G [00:16<00:36, 444MB/s]#015Downloading (…)\"pytorch_model.bin\";:  34%|███▎      | 8.17G/24.2G [00:16<00:36, 436MB/s]#015Downloading (…)\"pytorch_model.bin\";:  34%|███▍      | 8.22G/24.2G [00:16<00:36, 438MB/s]#015Downloading (…)\"pytorch_model.bin\";:  34%|███▍      | 8.27G/24.2G [00:17<00:36, 441MB/s]#015Downloading (…)\"pytorch_model.bin\";:  34%|███▍      | 8.33G/24.2G [00:17<00:35, 443MB/s]#015Downloading (…)\"pytorch_model.bin\";:  35%|███▍      | 8.38G/24.2G [00:17<00:35, 444MB/s]#015Downloading (…)\"pytorch_model.bin\";:  35%|███▍      | 8.43G/24.2G [00:17<00:35, 445MB/s]#015Downloading (…)\"pytorch_model.bin\";:  35%|███▌      | 8.48G/24.2G [00:17<00:35, 446MB/s]#015Downloading (…)\"pytorch_model.bin\";:  35%|███▌      | 8.54G/24.2G [00:17<00:34, 450MB/s]#015Downloading (…)\"pytorch_model.bin\";:  35%|███▌      | 8.59G/24.2G [00:17<00:33, 466MB/s]#015Downloading (…)\"pytorch_model.bin\";:  36%|███▌      | 8.64G/24.2G [00:17<00:33, 466MB/s]#015Downloading (…)\"pytorch_model.bin\";:  36%|███▌      | 8.69G/24.2G [00:17<00:32, 473MB/s]#015Downloading (…)\"pytorch_model.bin\";:  36%|███▌      | 8.75G/24.2G [00:18<00:34, 446MB/s]#015Downloading (…)\"pytorch_model.bin\";:  36%|███▋      | 8.80G/24.2G [00:18<00:33, 459MB/s]#015Downloading (…)\"pytorch_model.bin\";:  37%|███▋      | 8.85G/24.2G [00:18<00:33, 465MB/s]#015Downloading (…)\"pytorch_model.bin\";:  37%|███▋      | 8.90G/24.2G [00:18<00:32, 472MB/s]#015Downloading (…)\"pytorch_model.bin\";:  37%|███▋      | 8.95G/24.2G [00:18<0\u001b[0m\n",
      "\u001b[34m0:31, 477MB/s]#015Downloading (…)\"pytorch_model.bin\";:  37%|███▋      | 9.01G/24.2G [00:18<00:31, 481MB/s]#015Downloading (…)\"pytorch_model.bin\";:  37%|███▋      | 9.06G/24.2G [00:18<00:31, 486MB/s]#015Downloading (…)\"pytorch_model.bin\";:  38%|███▊      | 9.11G/24.2G [00:18<00:30, 488MB/s]#015Downloading (…)\"pytorch_model.bin\";:  38%|███▊      | 9.16G/24.2G [00:18<00:30, 490MB/s]#015Downloading (…)\"pytorch_model.bin\";:  38%|███▊      | 9.22G/24.2G [00:19<00:30, 492MB/s]#015Downloading (…)\"pytorch_model.bin\";:  38%|███▊      | 9.27G/24.2G [00:19<00:30, 493MB/s]#015Downloading (…)\"pytorch_model.bin\";:  39%|███▊      | 9.32G/24.2G [00:19<00:30, 495MB/s]#015Downloading (…)\"pytorch_model.bin\";:  39%|███▊      | 9.37G/24.2G [00:19<00:29, 497MB/s]#015Downloading (…)\"pytorch_model.bin\";:  39%|███▉      | 9.43G/24.2G [00:19<00:29, 496MB/s]#015Downloading (…)\"pytorch_model.bin\";:  39%|███▉      | 9.48G/24.2G [00:19<00:29, 497MB/s]#015Downloading (…)\"pytorch_model.bin\";:  39%|███▉      | 9.53G/24.2G [00:19<00:29, 498MB/s]#015Downloading (…)\"pytorch_model.bin\";:  40%|███▉      | 9.58G/24.2G [00:19<00:29, 495MB/s]#015Downloading (…)\"pytorch_model.bin\";:  40%|███▉      | 9.64G/24.2G [00:19<00:29, 494MB/s]#015Downloading (…)\"pytorch_model.bin\";:  40%|████      | 9.69G/24.2G [00:19<00:29, 498MB/s]#015Downloading (…)\"pytorch_model.bin\";:  40%|████      | 9.74G/24.2G [00:20<00:28, 502MB/s]#015Downloading (…)\"pytorch_model.bin\";:  40%|████      | 9.79G/24.2G [00:20<00:28, 504MB/s]#015Downloading (…)\"pytorch_model.bin\";:  41%|████      | 9.85G/24.2G [00:20<00:28, 506MB/s]#015Downloading (…)\"pytorch_model.bin\";:  41%|████      | 9.90G/24.2G [00:20<00:45, 315MB/s]#015Downloading (…)\"pytorch_model.bin\";:  41%|████      | 9.95G/24.2G [00:20<00:40, 355MB/s]#015Downloading (…)\"pytorch_model.bin\";:  41%|████▏     | 10.0G/24.2G [00:20<00:36, 390MB/s]#015Downloading (…)\"pytorch_model.bin\";:  42%|████▏     | 10.1G/24.2G [00:20<00:33, 420MB/s]#015Downloading (…)\"pytorch_model.bin\";:  42%|████▏     | 10.1G/24.2G [00:20<00:31, 444MB/s]#015Downloading (…)\"pytorch_model.bin\";:  42%|████▏     | 10.2G/24.2G [00:21<00:30, 461MB/s]#015Downloading (…)\"pytorch_model.bin\";:  42%|████▏     | 10.2G/24.2G [00:21<00:29, 472MB/s]#015Downloading (…)\"pytorch_model.bin\";:  42%|████▏     | 10.3G/24.2G [00:21<00:28, 483MB/s]#015Downloading (…)\"pytorch_model.bin\";:  43%|████▎     | 10.3G/24.2G [00:21<00:28, 483MB/s]#015Downloading (…)\"pytorch_model.bin\";:  43%|████▎     | 10.4G/24.2G [00:21<00:29, 473MB/s]#015Downloading (…)\"pytorch_model.bin\";:  43%|████▎     | 10.4G/24.2G [00:21<00:29, 463MB/s]#015Downloading (…)\"pytorch_model.bin\";:  43%|████▎     | 10.5G/24.2G [00:21<00:29, 459MB/s]#015Downloading (…)\"pytorch_model.bin\";:  43%|████▎     | 10.5G/24.2G [00:21<00:29, 456MB/s]#015Downloading (…)\"pytorch_model.bin\";:  44%|████▎     | 10.6G/24.2G [00:21<00:30, 453MB/s]#015Downloading (…)\"pytorch_model.bin\";:  44%|████▍     | 10.6G/24.2G [00:22<00:29, 460MB/s]#015Downloading (…)\"pytorch_model.bin\";:  44%|████▍     | 10.7G/24.2G [00:22<00:28, 474MB/s]#015Downloading (…)\"pytorch_model.bin\";:  44%|████▍     | 10.7G/24.2G [00:22<00:28, 467MB/s]#015Downloading (…)\"pytorch_model.bin\";:  45%|████▍     | 10.8G/24.2G [00:22<00:28, 476MB/s]#015Downloading (…)\"pytorch_model.bin\";:  45%|████▍     | 10.8G/24.2G [00:22<00:27, 486MB/s]#015Downloading (…)\"pytorch_model.bin\";:  45%|████▌     | 10.9G/24.2G [00:22<00:27, 492MB/s]#015Downloading (…)\"pytorch_model.bin\";:  45%|████▌     | 10.9G/24.2G [00:22<00:26, 497MB/s]#015Downloading (…)\"pytorch_model.bin\";:  45%|████▌     | 11.0G/24.2G [00:22<00:26, 500MB/s]#015Downloading (…)\"pytorch_model.bin\";:  46%|████▌     | 11.1G/24.2G [00:22<00:26, 503MB/s]#015Downloading (…)\"pytorch_model.bin\";:  46%|████▌     | 11.1G/24.2G [00:23<00:25, 505MB/s]#015Downloading (…)\"pytorch_model.bin\";:  46%|████▌     | 11.2G/24.2G [00:23<00:25, 507MB/s]#015Downloading (…)\"pytorch_model.bin\";:  46%|████▋     | 11.2G/24.2G [00:23<00:25, 507MB/s]#015Downloading (…)\"pytorch_model.bin\";:  47%|████▋     | 11.3G/24.2G [00:23<00:25, 507MB/s]#015Downloading (…)\"pytorch_model.bin\";:  47%|████▋     | 11.3G/24.2G [00:23<00:25, 507MB/s]#015Downloading (…)\"pytorch_model.bin\";:  47%|████▋     | 11.4G/24.2G [00:23<00:25, 508MB/s]#015Downloading (…)\"pytorch_model.bin\";:  47%|████▋     | 11.4G/24.2G [00:23<00:25, 508MB/s]#015Downloading (…)\"pytorch_model.bin\";:  47%|████▋     | 11.5G/24.2G [00:23<00:25, 508MB/s]#015Downloading (…)\"pytorch_model.bin\";:  48%|████▊     | 11.5G/24.2G [00:23<00:25, 498MB/s]#015Downloading (…)\"pytorch_model.bin\";:  48%|████▊     | 11.6G/24.2G [00:23<00:25, 497MB/s]#015Downloading (…)\"pytorch_model.bin\";:  48%|████▊     | 11.6G/24.2G [00:24<00:25, 501MB/s]#015Downloading (…)\"pytorch_model.bin\";:  48%|████▊     | 11.7G/24.2G [00:24<00:24, 504MB/s]#015Downloading (…)\"pytorch_model.bin\";:  48%|████▊     | 11.7G/24.2G [00:24<00:24, 506MB/s]#015Downloading (…)\"pytorch_model.bin\";:  49%|████▊     | 11.8G/24.2G [00:24<00:24, 508MB/s]#015Downloading (…)\"pytorch_model.bin\";:  49%|████▉     | 11.8G/24.2G [00:24<00:24, 508MB/s]#015Downloading (…)\"pytorch_model.bin\";:  49%|████▉     | 11.9G/24.2G [00:24<00:24, 509MB/s]#015Downloading (…)\"pytorch_model.bin\";:  49%|████▉     | 11.9G/24.2G [00:24<00:24, 510MB/s]#015Downloading (…)\"pytorch_model.bin\";:  50%|████▉     | 12.0G/24.2G [00:24<00:24, 509MB/s]#015Downloading (…)\"pytorch_model.bin\";:  50%|████▉     | 12.0G/24.2G [00:24<00:23, 507MB/s]#015Downloading (…)\"pytorch_model.bin\";:  50%|████▉     | 12.1G/24.2G [00:25<00:24, 502MB/s]#015Downloading (…)\"pytorch_model.bin\";:  50%|█████     | 12.2G/24.2G [00:25<00:24, 500MB/s]#015Downloading (…)\"pytorch_model.bin\";:  50%|█████     | 12.2G/24.2G [00:25<00:24, 498MB/s]#015Downloading (…)\"pytorch_model.bin\";:  51%|█████     | 12.3G/24.2G [00:25<00:24, 496MB/s]#015Downloading (…)\"pytorch_model.bin\";:  51%|█████     | 12.3G/24.2G [00:25<00:23, 496MB/s]#015Downloading (…)\"pytorch_model.bin\";:  51%|█████     | 12.4G/24.2G [00:25<00:23, 498MB/s]#015Downloading (…)\"pytorch_model.bin\";:  51%|█████▏    | 12.4G/24.2G [00:25<00:23, 498MB/s]#015Downloading (…)\"pytorch_model.bin\";:  52%|█████▏    | 12.5G/24.2G [00:25<00:23, 498MB/s]#015Downloading (…)\"pytorch_model.bin\";:  52%|█████▏    | 12.5G/24.2G [00:25<00:23, 496MB/s]#015Downloading (…)\"pytorch_model.bin\";:  52%|█████▏    | 12.6G/24.2G [00:25<00:23, 495MB/s]#015Downloading (…)\"pytorch_model.bin\";:  52%|█████▏    | 12.6G/24.2G [00:26<00:23, 497MB/s]#015Downloading (…)\"pytorch_model.bin\";:  52%|█████▏    | 12.7G/24.2G [00:26<00:23, 497MB/s]#015Downloading (…)\"pytorch_model.bin\";:  53%|█████▎    | 12.7G/24.2G [00:26<00:23, 498MB/s]#015Downloading (…)\"pytorch_model.bin\";:  53%|█████▎    | 12.8G/24.2G [00:26<00:23, 496MB/s]#015Downloading (…)\"pytorch_model.bin\";:  53%|█████▎    | 12.8G/24.2G [00:26<00:22, 496MB/s]#015Downloading (…)\"pytorch_model.bin\";:  53%|█████▎    | 12.9G/24.2G [00:26<00:23, 472MB/s]#015Downloading (…)\"pytorch_model.bin\";:  53%|█████▎    | 12.9G/24.2G [00:26<00:23, 479MB/s]#015Downloading (…)\"pytorch_model.bin\";:  54%|█████▎    | 13.0G/24.2G [00:26<00:23, 484MB/s]#015Downloading (…)\"pytorch_model.bin\";:  54%|█████▍    | 13.0G/24.2G [00:26<00:22, 488MB/s]#015Downloading (…)\"pytorch_model.bin\";:  54%|█████▍    | 13.1G/24.2G [00:27<00:22, 485MB/s]#015Downloading (…)\"pytorch_model.bin\";:  54%|█████▍    | 13.1G/24.2G [00:27<00:22, 485MB/s]#015Downloading (…)\"pytorch_model.bin\";:  55%|█████▍    | 13.2G/24.2G [00:27<00:22, 492MB/s]#015Downloading (…)\"pytorch_model.bin\";:  55%|█████▍    | 13.3G/24.2G [00:27<00:22, 497MB/s]#015Downloading (…)\"pytorch_model.bin\";:  55%|█████▍    | 13.3G/24.2G [00:27<00:21, 501MB/s]#015Downloading (…)\"pytorch_model.bin\";:  55%|█████▌    | 13.4G/24.2G [00:27<00:21, 505MB/s]#015Downloading (…)\"pytorch_model.bin\";:  55%|█████▌    | 13.4G/24.2G [00:27<00:21, 491MB/s]#015Downloading (…)\"pytorch_model.bin\";:  56%|█████▌    | 13.5G/24.2G [00:27<00:22, 488MB/s]#015Downloading (…)\"pytorch_model.bin\";:  56%|█████▌    | 13.5G/24.2G [00:27<00:21, 494MB/s]#015Downloading (…)\"pytorch_model.bin\";:  56%|█████▌    | 13.6G/24.2G [00:27<00:21, 496MB/s]#015Downloading (…)\"pytorch_model.bin\";:  56%|█████▋    | 13.6G/24.2G [00:28<00:21, 499MB/s]#015Downloading (…)\"pytorch_model.bin\";:  56%|█████▋    | 13.7G/24.2G [00:28<00:20, 502MB/s]#015Downloading (…)\"pytorch_model.bin\";:  57%|█████▋    | 13.7G/24.2G [00:28<00:20, 506MB/s]#015Downloading (…)\"pytorch_model.bin\";:  57%|█████▋    | 13.8G/24.2G [00:28<00:20, 506MB/s]#015Downloading (…)\"pytorch_model.bin\";:  57%|█████▋    | 13.8G/24.2G [00:28<00:20, 496MB/s]#015Downloading (…)\"pytorch_model.bin\";:  57%|█████▋    | 13.9G/24.2G [00:28<00:29, 348MB/s]#015Downloading (…)\"pytorch_model.bin\";:  58%|█████▊    | 13.9G/24.2G [00:28<00:26, 384MB/s]#015Downloading (…)\"pytorch_model.bin\";:  58%|█████▊    | 14.0G/24.2G [00:28<00:24, 414MB/s]#015Downloading (…)\"pytorch_model.bin\";:  58%|█████▊    | 14.0G/24.2G [00:29<00:23, 438MB/s]#015Downloading (…)\"pytorch_model.bin\";:  58%|█████▊    | 14.1G/24.2G [00:29<00:22, 457MB/s]#015Downloading (…)\"pytorch_model.bin\";:  58%|█████▊    | 14.1G/24.2G [00:29<00:21, 471MB/s]#015Downloading (…)\"pytorch_model.bin\";:  59%|█████▊    | 14.2G/24.2G [00:29<00:20, 482MB/s]#015Downloading (…)\"pytorch_model.bin\";:  59%|█████▉    | 14.3G/24.2G [00:29<00:20, 490MB/s]#015Downloading (…)\"pytorch_model.bin\";:  59%|█████▉    | 14.3G/24.2G [00:29<00:20, 491MB/s]#015Downloading (…)\"pytorch_model.bin\";:  59%|█████▉    | 14.4G/24.2G [00:29<00:19, 496MB/s]#015Downloading (…)\"pytorch_model.bin\";:  60%|█████▉    | 14.4G/24.2G [00:29<00:19, 498MB/s]#015Downloading (…)\"pytorch_model.bin\";:  60%|█████▉    | 14.5G/24.2G [00:29<00:19, 501MB/s]#015Downloading (…)\"pytorch_model.bin\";:  60%|█████▉    | 14.5G/24.2G [00:30<00:20, 484MB/s]#015Downloading (…)\"pytorch_model.bin\";:  60%|██████    | 14.6G/24.2G [00:30<00:20, 478MB/s]#015Downloading (…)\"pytorch_model.bin\";:  60%|██████    | 14.6G/24.2G [00:30<00:19, 487MB/s]#015Downloading (…)\"pytorch_model.bin\";:  61%|██████    | 14.7G/24.2G [00:30<00:19, 492MB/s]#015Downloading (…)\"pytorch_model.bin\";:  61%|██████    | 14.7G/24.2G [00:30<00:19, 498MB/s]#015Downloading (…)\"pytorch_model.bin\";:  61%|██████    | 14.8G/24.2G [00:30<00:29, 316MB/s]#015Downloading (…)\"pytorch_model.bin\";:  61%|██████    | 14.8G/24.2G [00:30<00:26, 356MB/s]#015Downloading (…)\"pytorch_model.bin\";:  61%|██████▏   | 14.9G/24.2G [00:30<00:23, 391MB/s]#015Downloading (…)\"pytorch_model.bin\";:  62%|██████▏   | 14.9G/24.2G [00:31<00:22, 419MB/s]#015Downloading (…)\"pytorch_model.bin\";:  62%|██████▏   | 15.0G/24.2G [00:31<00:20, 444MB/s]#015Downloading (…)\"pytorch_model.bin\";:  62%|██████▏   | 15.0G/24.2G [00:31<00:19, 462MB/s]#015Downloading (…)\"pytorch_model.bin\";:  62%|██████▏   | 15.1G/24.2G [00:31<00:19, 472MB/s]#015Downloading (…)\"pytorch_model.bin\";:  63%|██████▎   | 15.1G/24.2G [00:31<00:18, 483MB/s]#015Downloading (…)\"pytorch_model.bin\";:  63%|██████▎   | 15.2G/24.2G [00:31<00:18, 491MB/s]#015Downloading (…)\"pytorch_model.bin\";:  63%|██████▎   | 15.2G/24.2G [00:31<00:18, 496MB/s]#015Downloading (…)\"pytorch_model.bin\";:  63%|██████▎   | 15.3G/24.2G [00:31<00:17, 498MB/s]#015Downloading (…)\"pytorch_model.bin\";:  63%|██████▎   | 15.4G/24.2G [00:31<00:18, 484MB/s]#015Downloading (…)\"pytorch_model.bin\";:  64%|██████▎   | 15.4G/24.2G [00:32<00:20, 427MB/s]#015Downloading (…)\"pytorch_model.bin\";:  64%|██████▍   | 15.5G/24.2G [00:32<00:19, 450MB/s]#015Downloading (…)\"pytorch_model.bin\";:  64%|██████▍   | 15.5G/24.2G [00:32<00:19, 455MB/s]#015Downloading (…)\"pytorch_model.bin\";:  64%|██████▍   | 15.6G/24.2G [00:32<00:18, 469MB/s]#015Downloading (…)\"pytorch_model.bin\";:  64%|██████▍   | 15.6G/24.2G [00:32<00:17, 481MB/s]#015Downloading (…)\"pytorch_model.bin\";:  65%|██████▍   | 15.7G/24.2G [00:32<00:17, 490MB/s]#015Downloading (…)\"pytorch_model.bin\";:  65%|██████▍   | 15.7G/24.2G [00:32<00:17, 498MB/s]#015Downloading (…)\"pytorch_model.bin\";:  65%|██████▌   | 15.8G/24.2G [00:32<00:18, 456MB/s]#015Downloading (…)\"pytorch_model.bin\";:  65%|██████▌   | 15.8G/24.2G [00:32<00:17, 467MB/s]#015Downloading (…)\"pytorch_model.bin\";:  66%|██████▌   | 15.9G/24.2G [00:33<00:19, 436MB/s]#015Downloading (…)\"pytorch_model.bin\";:  66%|██████▌   | 15.9G/24.2G [00:33<00:19, 435MB/s]#015Downloading (…)\"pytorch_model.bin\";:  66%|██████▌   | 16.0G/24.2G [00:33<00:20, 410MB/s]#015Downloading (…)\"pytorch_model.bin\";:  66%|██████▌   | 16.0G/24.2G [00:33<00:18, 434MB/s]#015Downloading (…)\"pytorch_model.bin\";:  66%|██████▋   | 16.1G/24.2G [00:33<00:17, 456MB/s]#015Downloading (…)\"pytorch_model.bin\";:  67%|██████▋   | 16.1G/24.2G [00:33<00:17, 472MB/s]#015Downloading (…)\"pytorch_model.bin\";:  67%|██████▋   | 16.2G/24.2G [00:33<00:16, 482MB/s]#015Downloading (…)\"pytorch_model.bin\";:  67%|██████▋   | 16.2G/24.2G [00:33<00:16, 483MB/s]#015Downloading (…)\"pytorch_model.bin\";:  67%|██████▋   | 16.3G/24.2G [00:33<00:16, 484MB/s]#015Downloading (…)\"pytorch_model.bin\";:  68%|██████▊   | 16.3G/24.2G [00:34<00:16, 490MB/s]#015Downloading (…)\"pytorch_model.bin\";:  68%|██████▊   | 16.4G/24.2G [00:34<00:15, 503MB/s]#015Downloading (…)\"pytorch_model.bin\";:  68%|██████▊   | 16.5G/24.2G [00:34<00:15, 513MB/s]#015Downloading (…)\"pytorch_model.bin\";:  68%|██████▊   | 16.5G/24.2G [00:34<00:14, 514MB/s]#015Downloading (…)\"pytorch_model.bin\";:  69%|██████▊   | 16.6G/24.2G [00:34<00:14, 520MB/s]#015Downloading (…)\"pytorch_model.bin\";:  69%|██████▉   | 16.7G/24.2G [00:34<00:14, 523MB/s]#015Downloading (…)\"pytorch_model.bin\";:  69%|██████▉   | 16.7G/24.2G [00:34<00:14, 518MB/s]#015Downloading (…)\"pytorch_model.bin\";:  69%|██████▉   | 16.8G/24.2G [00:34<00:14, 522MB/s]#015Downloading (…)\"pytorch_model.bin\";:  70%|██████▉   | 16.8G/24.2G [00:34<00:14, 524MB/s]#015Downloading (…)\"pytorch_model.bin\";:  70%|██████▉   | 16.9G/24.2G [00:35<00:13, 527MB/s]#015Downloading (…)\"pytorch_model.bin\";:  70%|███████   | 17.0G/24.2G [00:35<00:13, 526MB/s]#015Downloading (…)\"pytorch_model.bin\";:  70%|███████   | 17.0G/24.2G [00:35<00:13, 528MB/s]#015Downloading (…)\"pytorch_model.bin\";:  71%|███████   | 17.1G/24.2G [00:35<00:13, 528MB/s]#015Downloading (…)\"pytorch_model.bin\";:  71%|███████   | 17.1G/24.2G [00:35<00:13, 525MB/s]#015Downloading (…)\"pytorch_model.bin\";:  71%|███████   | 17.2G/24.2G [00:35<00:14, 487MB/s]#015Downloading (…)\"pytorch_model.bin\";:  71%|███████▏  | 17.3G/24.2G [00:35<00:14, 473MB/s]#015Downloading (…)\"pytorch_model.bin\";:  72%|███████▏  | 17.3G/24.2G [00:35<00:15, 458MB/s]#015Downloading (…)\"pytorch_model.bin\";:  72%|███████▏  | 17.4G/24.2G [00:36<00:15, 443MB/s]#015Downloading (…)\"pytorch_model.bin\";:  72%|███████▏  | 17.4G/24.2G [00:36<00:14, 458MB/s]#015Downloading (…)\"pytorch_model.bin\";:  72%|████�\u001b[0m\n",
      "\u001b[34m�██▏  | 17.5G/24.2G [00:36<00:14, 477MB/s]#015Downloading (…)\"pytorch_model.bin\";:  72%|███████▏  | 17.5G/24.2G [00:36<00:14, 470MB/s]#015Downloading (…)\"pytorch_model.bin\";:  73%|███████▎  | 17.6G/24.2G [00:36<00:14, 470MB/s]#015Downloading (…)\"pytorch_model.bin\";:  73%|███████▎  | 17.6G/24.2G [00:36<00:14, 469MB/s]#015Downloading (…)\"pytorch_model.bin\";:  73%|███████▎  | 17.7G/24.2G [00:36<00:13, 483MB/s]#015Downloading (…)\"pytorch_model.bin\";:  73%|███████▎  | 17.7G/24.2G [00:36<00:13, 495MB/s]#015Downloading (…)\"pytorch_model.bin\";:  74%|███████▎  | 17.8G/24.2G [00:36<00:12, 502MB/s]#015Downloading (…)\"pytorch_model.bin\";:  74%|███████▍  | 17.9G/24.2G [00:37<00:12, 511MB/s]#015Downloading (…)\"pytorch_model.bin\";:  74%|███████▍  | 17.9G/24.2G [00:37<00:12, 515MB/s]#015Downloading (…)\"pytorch_model.bin\";:  74%|███████▍  | 18.0G/24.2G [00:37<00:11, 520MB/s]#015Downloading (…)\"pytorch_model.bin\";:  75%|███████▍  | 18.0G/24.2G [00:37<00:11, 519MB/s]#015Downloading (…)\"pytorch_model.bin\";:  75%|███████▍  | 18.1G/24.2G [00:37<00:11, 523MB/s]#015Downloading (…)\"pytorch_model.bin\";:  75%|███████▍  | 18.2G/24.2G [00:37<00:11, 523MB/s]#015Downloading (…)\"pytorch_model.bin\";:  75%|███████▌  | 18.2G/24.2G [00:37<00:11, 500MB/s]#015Downloading (…)\"pytorch_model.bin\";:  75%|███████▌  | 18.3G/24.2G [00:37<00:12, 495MB/s]#015Downloading (…)\"pytorch_model.bin\";:  76%|███████▌  | 18.3G/24.2G [00:38<00:12, 474MB/s]#015Downloading (…)\"pytorch_model.bin\";:  76%|███████▌  | 18.4G/24.2G [00:38<00:12, 466MB/s]#015Downloading (…)\"pytorch_model.bin\";:  76%|███████▌  | 18.4G/24.2G [00:38<00:12, 466MB/s]#015Downloading (…)\"pytorch_model.bin\";:  76%|███████▋  | 18.5G/24.2G [00:38<00:12, 467MB/s]#015Downloading (…)\"pytorch_model.bin\";:  77%|███████▋  | 18.5G/24.2G [00:38<00:11, 485MB/s]#015Downloading (…)\"pytorch_model.bin\";:  77%|███████▋  | 18.6G/24.2G [00:38<00:11, 498MB/s]#015Downloading (…)\"pytorch_model.bin\";:  77%|███████▋  | 18.7G/24.2G [00:38<00:10, 509MB/s]#015Downloading (…)\"pytorch_model.bin\";:  77%|███████▋  | 18.7G/24.2G [00:38<00:10, 512MB/s]#015Downloading (…)\"pytorch_model.bin\";:  78%|███████▊  | 18.8G/24.2G [00:38<00:10, 502MB/s]#015Downloading (…)\"pytorch_model.bin\";:  78%|███████▊  | 18.8G/24.2G [00:39<00:10, 492MB/s]#015Downloading (…)\"pytorch_model.bin\";:  78%|███████▊  | 18.9G/24.2G [00:39<00:10, 499MB/s]#015Downloading (…)\"pytorch_model.bin\";:  78%|███████▊  | 18.9G/24.2G [00:39<00:10, 502MB/s]#015Downloading (…)\"pytorch_model.bin\";:  78%|███████▊  | 19.0G/24.2G [00:39<00:10, 506MB/s]#015Downloading (…)\"pytorch_model.bin\";:  79%|███████▊  | 19.0G/24.2G [00:39<00:10, 510MB/s]#015Downloading (…)\"pytorch_model.bin\";:  79%|███████▉  | 19.1G/24.2G [00:39<00:10, 512MB/s]#015Downloading (…)\"pytorch_model.bin\";:  79%|███████▉  | 19.1G/24.2G [00:39<00:09, 514MB/s]#015Downloading (…)\"pytorch_model.bin\";:  79%|███████▉  | 19.2G/24.2G [00:39<00:09, 515MB/s]#015Downloading (…)\"pytorch_model.bin\";:  79%|███████▉  | 19.2G/24.2G [00:39<00:09, 514MB/s]#015Downloading (…)\"pytorch_model.bin\";:  80%|███████▉  | 19.3G/24.2G [00:39<00:09, 515MB/s]#015Downloading (…)\"pytorch_model.bin\";:  80%|███████▉  | 19.3G/24.2G [00:40<00:09, 514MB/s]#015Downloading (…)\"pytorch_model.bin\";:  80%|████████  | 19.4G/24.2G [00:40<00:09, 511MB/s]#015Downloading (…)\"pytorch_model.bin\";:  80%|████████  | 19.5G/24.2G [00:40<00:09, 507MB/s]#015Downloading (…)\"pytorch_model.bin\";:  81%|████████  | 19.5G/24.2G [00:40<00:09, 503MB/s]#015Downloading (…)\"pytorch_model.bin\";:  81%|████████  | 19.6G/24.2G [00:40<00:09, 502MB/s]#015Downloading (…)\"pytorch_model.bin\";:  81%|████████  | 19.6G/24.2G [00:40<00:09, 500MB/s]#015Downloading (…)\"pytorch_model.bin\";:  81%|████████  | 19.7G/24.2G [00:40<00:09, 503MB/s]#015Downloading (…)\"pytorch_model.bin\";:  81%|████████▏ | 19.7G/24.2G [00:40<00:14, 315MB/s]#015Downloading (…)\"pytorch_model.bin\";:  82%|████████▏ | 19.8G/24.2G [00:41<00:12, 356MB/s]#015Downloading (…)\"pytorch_model.bin\";:  82%|████████▏ | 19.8G/24.2G [00:41<00:11, 391MB/s]#015Downloading (…)\"pytorch_model.bin\";:  82%|████████▏ | 19.9G/24.2G [00:41<00:10, 421MB/s]#015Downloading (…)\"pytorch_model.bin\";:  82%|████████▏ | 19.9G/24.2G [00:41<00:09, 444MB/s]#015Downloading (…)\"pytorch_model.bin\";:  83%|████████▎ | 20.0G/24.2G [00:41<00:09, 459MB/s]#015Downloading (…)\"pytorch_model.bin\";:  83%|████████▎ | 20.0G/24.2G [00:41<00:08, 471MB/s]#015Downloading (…)\"pytorch_model.bin\";:  83%|████████▎ | 20.1G/24.2G [00:41<00:08, 480MB/s]#015Downloading (…)\"pytorch_model.bin\";:  83%|████████▎ | 20.1G/24.2G [00:41<00:08, 489MB/s]#015Downloading (…)\"pytorch_model.bin\";:  83%|████████▎ | 20.2G/24.2G [00:41<00:08, 495MB/s]#015Downloading (…)\"pytorch_model.bin\";:  84%|████████▎ | 20.2G/24.2G [00:42<00:07, 500MB/s]#015Downloading (…)\"pytorch_model.bin\";:  84%|████████▍ | 20.3G/24.2G [00:42<00:07, 503MB/s]#015Downloading (…)\"pytorch_model.bin\";:  84%|████████▍ | 20.3G/24.2G [00:42<00:07, 506MB/s]#015Downloading (…)\"pytorch_model.bin\";:  84%|████████▍ | 20.4G/24.2G [00:42<00:07, 508MB/s]#015Downloading (…)\"pytorch_model.bin\";:  84%|████████▍ | 20.4G/24.2G [00:42<00:07, 508MB/s]#015Downloading (…)\"pytorch_model.bin\";:  85%|████████▍ | 20.5G/24.2G [00:42<00:07, 509MB/s]#015Downloading (…)\"pytorch_model.bin\";:  85%|████████▍ | 20.6G/24.2G [00:42<00:07, 510MB/s]#015Downloading (…)\"pytorch_model.bin\";:  85%|████████▌ | 20.6G/24.2G [00:42<00:07, 510MB/s]#015Downloading (…)\"pytorch_model.bin\";:  85%|████████▌ | 20.7G/24.2G [00:42<00:07, 502MB/s]#015Downloading (…)\"pytorch_model.bin\";:  86%|████████▌ | 20.7G/24.2G [00:42<00:07, 468MB/s]#015Downloading (…)\"pytorch_model.bin\";:  86%|████████▌ | 20.8G/24.2G [00:43<00:07, 458MB/s]#015Downloading (…)\"pytorch_model.bin\";:  86%|████████▌ | 20.8G/24.2G [00:43<00:07, 473MB/s]#015Downloading (…)\"pytorch_model.bin\";:  86%|████████▌ | 20.9G/24.2G [00:43<00:06, 482MB/s]#015Downloading (…)\"pytorch_model.bin\";:  86%|████████▋ | 20.9G/24.2G [00:43<00:06, 491MB/s]#015Downloading (…)\"pytorch_model.bin\";:  87%|████████▋ | 21.0G/24.2G [00:43<00:06, 496MB/s]#015Downloading (…)\"pytorch_model.bin\";:  87%|████████▋ | 21.0G/24.2G [00:43<00:06, 482MB/s]#015Downloading (…)\"pytorch_model.bin\";:  87%|████████▋ | 21.1G/24.2G [00:43<00:06, 469MB/s]#015Downloading (…)\"pytorch_model.bin\";:  87%|████████▋ | 21.1G/24.2G [00:43<00:06, 463MB/s]#015Downloading (…)\"pytorch_model.bin\";:  87%|████████▋ | 21.2G/24.2G [00:43<00:06, 457MB/s]#015Downloading (…)\"pytorch_model.bin\";:  88%|████████▊ | 21.2G/24.2G [00:44<00:06, 455MB/s]#015Downloading (…)\"pytorch_model.bin\";:  88%|████████▊ | 21.3G/24.2G [00:44<00:06, 455MB/s]#015Downloading (…)\"pytorch_model.bin\";:  88%|████████▊ | 21.3G/24.2G [00:44<00:06, 453MB/s]#015Downloading (…)\"pytorch_model.bin\";:  88%|████████▊ | 21.4G/24.2G [00:44<00:06, 451MB/s]#015Downloading (…)\"pytorch_model.bin\";:  89%|████████▊ | 21.4G/24.2G [00:44<00:06, 449MB/s]#015Downloading (…)\"pytorch_model.bin\";:  89%|████████▉ | 21.5G/24.2G [00:44<00:06, 449MB/s]#015Downloading (…)\"pytorch_model.bin\";:  89%|████████▉ | 21.5G/24.2G [00:44<00:05, 450MB/s]#015Downloading (…)\"pytorch_model.bin\";:  89%|████████▉ | 21.6G/24.2G [00:44<00:05, 450MB/s]#015Downloading (…)\"pytorch_model.bin\";:  89%|████████▉ | 21.7G/24.2G [00:45<00:05, 451MB/s]#015Downloading (…)\"pytorch_model.bin\";:  90%|████████▉ | 21.7G/24.2G [00:45<00:07, 342MB/s]#015Downloading (…)\"pytorch_model.bin\";:  90%|████████▉ | 21.8G/24.2G [00:45<00:06, 367MB/s]#015Downloading (…)\"pytorch_model.bin\";:  90%|█████████ | 21.8G/24.2G [00:45<00:06, 388MB/s]#015Downloading (…)\"pytorch_model.bin\";:  90%|█████████ | 21.9G/24.2G [00:45<00:05, 403MB/s]#015Downloading (…)\"pytorch_model.bin\";:  91%|█████████ | 21.9G/24.2G [00:45<00:05, 414MB/s]#015Downloading (…)\"pytorch_model.bin\";:  91%|█████████ | 22.0G/24.2G [00:45<00:05, 421MB/s]#015Downloading (…)\"pytorch_model.bin\";:  91%|█████████ | 22.0G/24.2G [00:45<00:05, 427MB/s]#015Downloading (…)\"pytorch_model.bin\";:  91%|█████████ | 22.1G/24.2G [00:46<00:04, 432MB/s]#015Downloading (…)\"pytorch_model.bin\";:  91%|█████████▏| 22.1G/24.2G [00:46<00:04, 434MB/s]#015Downloading (…)\"pytorch_model.bin\";:  92%|█████████▏| 22.2G/24.2G [00:46<00:04, 440MB/s]#015Downloading (…)\"pytorch_model.bin\";:  92%|█████████▏| 22.2G/24.2G [00:46<00:04, 444MB/s]#015Downloading (…)\"pytorch_model.bin\";:  92%|█████████▏| 22.3G/24.2G [00:46<00:04, 449MB/s]#015Downloading (…)\"pytorch_model.bin\";:  92%|█████████▏| 22.3G/24.2G [00:46<00:04, 452MB/s]#015Downloading (…)\"pytorch_model.bin\";:  92%|█████████▏| 22.4G/24.2G [00:46<00:04, 454MB/s]#015Downloading (…)\"pytorch_model.bin\";:  93%|█████████▎| 22.4G/24.2G [00:46<00:03, 456MB/s]#015Downloading (…)\"pytorch_model.bin\";:  93%|█████████▎| 22.5G/24.2G [00:47<00:03, 456MB/s]#015Downloading (…)\"pytorch_model.bin\";:  93%|█████████▎| 22.5G/24.2G [00:47<00:03, 458MB/s]#015Downloading (…)\"pytorch_model.bin\";:  93%|█████████▎| 22.6G/24.2G [00:47<00:03, 459MB/s]#015Downloading (…)\"pytorch_model.bin\";:  94%|█████████▎| 22.6G/24.2G [00:47<00:03, 457MB/s]#015Downloading (…)\"pytorch_model.bin\";:  94%|█████████▍| 22.7G/24.2G [00:47<00:03, 458MB/s]#015Downloading (…)\"pytorch_model.bin\";:  94%|█████████▍| 22.8G/24.2G [00:47<00:03, 459MB/s]#015Downloading (…)\"pytorch_model.bin\";:  94%|█████████▍| 22.8G/24.2G [00:47<00:03, 462MB/s]#015Downloading (…)\"pytorch_model.bin\";:  94%|█████████▍| 22.9G/24.2G [00:47<00:02, 463MB/s]#015Downloading (…)\"pytorch_model.bin\";:  95%|█████████▍| 22.9G/24.2G [00:47<00:02, 462MB/s]#015Downloading (…)\"pytorch_model.bin\";:  95%|█████████▍| 23.0G/24.2G [00:48<00:02, 463MB/s]#015Downloading (…)\"pytorch_model.bin\";:  95%|█████████▌| 23.0G/24.2G [00:48<00:02, 463MB/s]#015Downloading (…)\"pytorch_model.bin\";:  95%|█████████▌| 23.1G/24.2G [00:48<00:02, 464MB/s]#015Downloading (…)\"pytorch_model.bin\";:  96%|█████████▌| 23.1G/24.2G [00:48<00:02, 465MB/s]#015Downloading (…)\"pytorch_model.bin\";:  96%|█████████▌| 23.2G/24.2G [00:48<00:02, 466MB/s]#015Downloading (…)\"pytorch_model.bin\";:  96%|█████████▌| 23.2G/24.2G [00:48<00:02, 467MB/s]#015Downloading (…)\"pytorch_model.bin\";:  96%|█████████▌| 23.3G/24.2G [00:48<00:02, 464MB/s]#015Downloading (…)\"pytorch_model.bin\";:  96%|█████████▋| 23.3G/24.2G [00:48<00:01, 454MB/s]#015Downloading (…)\"pytorch_model.bin\";:  97%|█████████▋| 23.4G/24.2G [00:48<00:01, 459MB/s]#015Downloading (…)\"pytorch_model.bin\";:  97%|█████████▋| 23.4G/24.2G [00:49<00:01, 462MB/s]#015Downloading (…)\"pytorch_model.bin\";:  97%|█████████▋| 23.5G/24.2G [00:49<00:01, 463MB/s]#015Downloading (…)\"pytorch_model.bin\";:  97%|█████████▋| 23.5G/24.2G [00:49<00:01, 464MB/s]#015Downloading (…)\"pytorch_model.bin\";:  97%|█████████▋| 23.6G/24.2G [00:49<00:01, 465MB/s]#015Downloading (…)\"pytorch_model.bin\";:  98%|█████████▊| 23.6G/24.2G [00:49<00:01, 465MB/s]#015Downloading (…)\"pytorch_model.bin\";:  98%|█████████▊| 23.7G/24.2G [00:49<00:01, 464MB/s]#015Downloading (…)\"pytorch_model.bin\";:  98%|█████████▊| 23.8G/24.2G [00:49<00:00, 463MB/s]#015Downloading (…)\"pytorch_model.bin\";:  98%|█████████▊| 23.8G/24.2G [00:49<00:00, 462MB/s]#015Downloading (…)\"pytorch_model.bin\";:  99%|█████████▊| 23.9G/24.2G [00:49<00:00, 461MB/s]#015Downloading (…)\"pytorch_model.bin\";:  99%|█████████▉| 23.9G/24.2G [00:50<00:00, 465MB/s]#015Downloading (…)\"pytorch_model.bin\";:  99%|█████████▉| 24.0G/24.2G [00:50<00:00, 481MB/s]#015Downloading (…)\"pytorch_model.bin\";:  99%|█████████▉| 24.0G/24.2G [00:50<00:00, 497MB/s]#015Downloading (…)\"pytorch_model.bin\";:  99%|█████████▉| 24.1G/24.2G [00:50<00:00, 507MB/s]#015Downloading (…)\"pytorch_model.bin\";: 100%|█████████▉| 24.1G/24.2G [00:50<00:00, 513MB/s]#015Downloading (…)\"pytorch_model.bin\";: 100%|██████████| 24.2G/24.2G [00:50<00:00, 515MB/s]#015Downloading (…)\"pytorch_model.bin\";: 100%|██████████| 24.2G/24.2G [00:50<00:00, 478MB/s]\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:2275] 2023-02-09 06:42:08,984 >> loading weights file pytorch_model.bin from cache at /opt/ml/model/models--EleutherAI--gpt-j-6B/snapshots/6e35e2148e92edf096e94d39ac2b98ad59e25975/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:42:17,656] [WARNING] [config_utils.py:67:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:2356] 2023-02-09 06:42:19,349 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:42:19,349] [WARNING] [config_utils.py:67:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:42:19,349] [WARNING] [config_utils.py:67:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:42:19,349] [WARNING] [config_utils.py:67:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:543] 2023-02-09 06:42:19,352 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"use_cache\": false\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:42:32,138] [INFO] [partition_parameters.py:413:__exit__] finished initializing model with 6.05B parameters\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/torch/distributed/distributed_c10d.py:2387: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:2857] 2023-02-09 06:42:50,006 >> All model checkpoint weights were used when initializing GPTJForCausalLM.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:2865] 2023-02-09 06:42:50,006 >> All the weights of GPTJForCausalLM were initialized from the model checkpoint at EleutherAI/gpt-j-6B.\u001b[0m\n",
      "\u001b[34mIf your task is similar to the task the model of the checkpoint was trained on, you can already use GPTJForCausalLM for predictions without further training.\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:2522] 2023-02-09 06:42:50,033 >> Generation config file not found, using a generation config created from the model config.\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/32 [00:00<?, ?ba/s]#015  0%|          | 0/32 [00:00<?, ?ba/s]#015  0%|          | 0/32 [00:00<?, ?ba/s]#015  0%|          | 0/32 [00:00<?, ?ba/s]#015  3%|▎         | 1/32 [00:00<00:23,  1.31ba/s]#015  3%|▎         | 1/32 [00:00<00:24,  1.26ba/s]#015  3%|▎         | 1/32 [00:00<00:24,  1.26ba/s]#015  3%|▎         | 1/32 [00:00<00:24,  1.25ba/s]#015  6%|▋         | 2/32 [00:01<00:22,  1.36ba/s]#015  6%|▋         | 2/32 [00:01<00:22,  1.33ba/s]#015  6%|▋         | 2/32 [00:01<00:22,  1.32ba/s]#015  6%|▋         | 2/32 [00:01<00:23,  1.30ba/s]#015  9%|▉         | 3/32 [00:02<00:20,  1.42ba/s]#015  9%|▉         | 3/32 [00:02<00:20,  1.38ba/s]#015  9%|▉         | 3/32 [00:02<00:21,  1.38ba/s]#015  9%|▉         | 3/32 [00:02<00:21,  1.35ba/s]#015 12%|█▎        | 4/32 [00:02<00:19,  1.43ba/s]#015 12%|█▎        | 4/32 [00:02<00:20,  1.40ba/s]#015 12%|█▎        | 4/32 [00:02<00:20,  1.39ba/s]#015 12%|█▎        | 4/32 [00:02<00:20,  1.36ba/s]#015 16%|█▌        | 5/32 [00:03<00:18,  1.46ba/s]#015 16%|█▌        | 5/32 [00:03<00:18,  1.43ba/s]#015 16%|█▌        | 5/32 [00:03<00:18,  1.43ba/s]#015 16%|█▌        | 5/32 [00:03<00:19,  1.38ba/s]#015 19%|█▉        | 6/32 [00:04<00:17,  1.48ba/s]#015 19%|█▉        | 6/32 [00:04<00:18,  1.43ba/s]#015 19%|█▉        | 6/32 [00:04<00:18,  1.43ba/s]#015 19%|█▉        | 6/32 [00:04<00:18,  1.40ba/s]#015 22%|██▏       | 7/32 [00:04<00:16,  1.51ba/s]#015 22%|██▏       | 7/32 [00:04<00:17,  1.45ba/s]#015 22%|██▏       | 7/32 [00:04<00:17,  1.45ba/s]#015 22%|██▏       | 7/32 [00:05<00:17,  1.43ba/s]#015 25%|██▌       | 8/32 [00:05<00:15,  1.51ba/s]#015 25%|██▌       | 8/32 [00:05<00:16,  1.46ba/s]#015 25%|██▌       | 8/32 [00:05<00:16,  1.45ba/s]#015 25%|██▌       | 8/32 [00:05<00:16,  1.43ba/s]#015 28%|██▊       | 9/32 [00:06<00:15,  1.52ba/s]#015 28%|██▊       | 9/32 [00:06<00:15,  1.47ba/s]#015 28%|██▊       | 9/32 [00:06<00:15,  1.47ba/s]#015 28%|██▊       | 9/32 [00:06<00:15,  1.44ba/s]#015 31%|███▏      | 10/32 [00:06<00:14,  1.54ba/s]#015 31%|███▏      | 10/32 [00:06<00:14,  1.48ba/s]#015 31%|███▏      | 10/32 [00:06<00:14,  1.48ba/s]#015 31%|███▏      | 10/32 [00:07<00:15,  1.45ba/s]#015 34%|███▍      | 11/32 [00:07<00:13,  1.54ba/s]#015 34%|███▍      | 11/32 [00:07<00:14,  1.49ba/s]#015 34%|███▍      | 11/32 [00:07<00:14,  1.49ba/s]#015 34%|███▍      | 11/32 [00:07<00:14,  1.46ba/s]#015 38%|███▊      | 12/32 [00:08<00:12,  1.55ba/s]#015 38%|███▊      | 12/32 [00:08<00:13,  1.50ba/s]#015 38%|███▊      | 12/32 [00:08<00:13,  1.50ba/s]#015 38%|███▊      | 12/32 [00:08<00:13,  1.46ba/s]#015 41%|████      | 13/32 [00:08<00:12,  1.56ba/s]#015 41%|████      | 13/32 [00:08<00:12,  1.49ba/s]#015 41%|████      | 13/32 [00:08<00:12,  1.50ba/s]#015 41%|████      | 13/32 [00:09<00:12,  1.46ba/s]#015 44%|████▍     | 14/32 [00:09<00:11,  1.56ba/s]#015 44%|████▍     | 14/32 [00:09<00:11,  1.51ba/s]#015 44%|████▍     | 14/32 [00:09<00:11,  1.50ba/s]#015 44%|████▍     | 14/32 [00:09<00:12,  1.48ba/s]#015 47%|████▋     | 15/32 [00:09<00:10,  1.56ba/s]#015 47%|████▋     | 15/32 [00:10<00:11,  1.52ba/s]#015 47%|████▋     | 15/32 [00:10<00:11,  1.50ba/s]#015 47%|████▋     | 15/32 [00:10<00:11,  1.47ba/s]#015 50%|█████     | 16/32 [00:10<00:10,  1.57ba/s]#015 50%|█████     | 16/32 [00:10<00:10,  1.53ba/s]#015 50%|█████     | 16/32 [00:10<00:10,  1.52ba/s]#015 50%|█████     | 16/32 [00:11<00:10,  1.48ba/s]#015 53%|█████▎    | 17/32 [00:11<00:09,  1.57ba/s]#015 53%|█████▎    | 17/32 [00:11<00:09,  1.54ba/s]#015 53%|█████▎    | 17/32 [00:11<00:09,  1.53ba/s]#015 56%|█████▋    | 18/32 [00:11<00:08,  1.57ba/s]#015 53%|█████▎    | 17/32 [00:11<00:10,  1.49ba/s]#015 56%|█████▋    | 18/32 [00:12<00:09,  1.53ba/s]#015 56%|█████▋    | 18/32 [00:12<00:09,  1.48ba/s]#015 59%|█████▉    | 19/32 [00:12<00:08,  1.56ba/s]#015 56%|█████▋    | 18/32 [00:12<00:09,  1.49ba/s]#015 59%|█████▉    | 19/32 [00:12<00:08,  1.53ba/s]#015 59%|█████▉    | 19/32 [00:12<00:08,  1.50ba/s]#015 62%|██████▎   | 20/32 [00:13<00:07,  1.56ba/s]#015 59%|█████▉    | 19/32 [00:13<00:08,  1.49ba/s]#015 62%|██████▎   | 20/32 [00:13<00:07,  1.52ba/s]#015 62%|██████▎   | 20/32 [00:13<00:07,  1.51ba/s]#015 66%|██████▌   | 21/32 [00:13<00:07,  1.52ba/s]#015 62%|██████▎   | 20/32 [00:13<00:08,  1.44ba/s]#015 66%|██████▌   | 21/32 [00:14<00:07,  1.48ba/s]#015 66%|██████▌   | 21/32 [00:14<00:07,  1.53ba/s]#015 69%|██████▉   | 22/32 [00:14<00:06,  1.54ba/s]#015 66%|██████▌   | 21/32 [00:14<00:07,  1.47ba/s]#015 69%|██████▉   | 22/32 [00:14<00:06,  1.55ba/s]#015 69%|██████▉   | 22/32 [00:14<00:06,  1.50ba/s]#015 72%|███████▏  | 23/32 [00:15<00:05,  1.56ba/s]#015 69%|██████▉   | 22/32 [00:15<00:06,  1.48ba/s]#015 72%|███████▏  | 23/32 [00:15<00:05,  1.55ba/s]#015 72%|███████▏  | 23/32 [00:15<00:05,  1.51ba/s]#015 75%|███████▌  | 24/32 [00:15<00:05,  1.56ba/s]#015 72%|███████▏  | 23/32 [00:15<00:06,  1.49ba/s]#015 75%|███████▌  | 24/32 [00:16<00:05,  1.56ba/s]#015 75%|███████▌  | 24/32 [00:16<00:05,  1.51ba/s]#015 78%|███████▊  | 25/32 [00:16<00:04,  1.57ba/s]#015 75%|███████▌  | 24/32 [00:16<00:05,  1.49ba/s]#015 78%|███████▊  | 25/32 [00:16<00:04,  1.54ba/s]#015 78%|███████▊  | 25/32 [00:16<00:04,  1.52ba/s]#015 81%|████████▏ | 26/32 [00:16<00:03,  1.59ba/s]#015 78%|███████▊  | 25/32 [00:17<00:04,  1.49ba/s]#015 81%|████████▏ | 26/32 [00:17<00:03,  1.55ba/s]#015 81%|████████▏ | 26/32 [00:17<00:03,  1.52ba/s]#015 84%|████████▍ | 27/32 [00:17<00:03,  1.59ba/s]#015 81%|████████▏ | 26/32 [00:17<00:04,  1.50ba/s]#015 84%|████████▍ | 27/32 [00:18<00:03,  1.55ba/s]#015 84%|████████▍ | 27/32 [00:18<00:03,  1.54ba/s]#015 88%|████████▊ | 28/32 [00:18<00:02,  1.59ba/s]#015 84%|████████▍ | 27/32 [00:18<00:03,  1.51ba/s]#015 88%|████████▊ | 28/32 [00:18<00:02,  1.54ba/s]#015 88%|████████▊ | 28/32 [00:18<00:02,  1.53ba/s]#015 91%|█████████ | 29/32 [00:18<00:01,  1.60ba/s]#015 88%|████████▊ | 28/32 [00:19<00:02,  1.51ba/s]#015 91%|█████████ | 29/32 [00:19<00:01,  1.54ba/s]#015 91%|█████████ | 29/32 [00:19<00:01,  1.53ba/s]#015 94%|█████████▍| 30/32 [00:19<00:01,  1.59ba/s]#015 91%|█████████ | 29/32 [00:19<00:01,  1.51ba/s]#015 94%|█████████▍| 30/32 [00:20<00:01,  1.55ba/s]#015 97%|█████████▋| 31/32 [00:20<00:00,  1.59ba/s]#015 94%|█████████▍| 30/32 [00:20<00:01,  1.53ba/s]#015 94%|█████████▍| 30/32 [00:20<00:01,  1.51ba/s]#015100%|██████████| 32/32 [00:20<00:00,  1.68ba/s]#015100%|██████████| 32/32 [00:20<00:00,  1.55ba/s]\u001b[0m\n",
      "\u001b[34m#015 97%|█████████▋| 31/32 [00:20<00:00,  1.54ba/s]#015 97%|█████████▋| 31/32 [00:20<00:00,  1.54ba/s]#015 97%|█████████▋| 31/32 [00:21<00:00,  1.52ba/s]#015100%|██████████| 32/32 [00:21<00:00,  1.63ba/s]#015100%|██████████| 32/32 [00:21<00:00,  1.51ba/s]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 32/32 [00:21<00:00,  1.62ba/s]#015100%|██████████| 32/32 [00:21<00:00,  1.50ba/s]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 32/32 [00:21<00:00,  1.61ba/s]#015100%|██████████| 32/32 [00:21<00:00,  1.47ba/s]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/8 [00:00<?, ?ba/s]#015 12%|█▎        | 1/8 [00:00<00:04,  1.68ba/s]#015  0%|          | 0/8 [00:00<?, ?ba/s]#015  0%|          | 0/8 [00:00<?, ?ba/s]#015  0%|          | 0/8 [00:00<?, ?ba/s]#015 25%|██▌       | 2/8 [00:01<00:03,  1.62ba/s]#015 12%|█▎        | 1/8 [00:00<00:04,  1.61ba/s]#015 12%|█▎        | 1/8 [00:00<00:04,  1.61ba/s]#015 12%|█▎        | 1/8 [00:00<00:04,  1.60ba/s]#015 38%|███▊      | 3/8 [00:01<00:03,  1.61ba/s]#015 25%|██▌       | 2/8 [00:01<00:03,  1.55ba/s]#015 25%|██▌       | 2/8 [00:01<00:03,  1.57ba/s]#015 25%|██▌       | 2/8 [00:01<00:03,  1.55ba/s]#015 50%|█████     | 4/8 [00:02<00:02,  1.61ba/s]#015 38%|███▊      | 3/8 [00:01<00:03,  1.56ba/s]#015 38%|███▊      | 3/8 [00:01<00:03,  1.57ba/s]#015 38%|███▊      | 3/8 [00:01<00:03,  1.55ba/s]#015 62%|██████▎   | 5/8 [00:03<00:01,  1.62ba/s]#015 50%|█████     | 4/8 [00:02<00:02,  1.56ba/s]#015 50%|█████     | 4/8 [00:02<00:02,  1.57ba/s]#015 50%|█████     | 4/8 [00:02<00:02,  1.54ba/s]#015 75%|███████▌  | 6/8 [00:03<00:01,  1.61ba/s]#015 62%|██████▎   | 5/8 [00:03<00:01,  1.56ba/s]#015 62%|██████▎   | 5/8 [00:03<00:01,  1.57ba/s]#015 88%|████████▊ | 7/8 [00:04<00:00,  1.61ba/s]#015 62%|██████▎   | 5/8 [00:03<00:01,  1.54ba/s]#015 75%|███████▌  | 6/8 [00:03<00:01,  1.57ba/s]#015 75%|███████▌  | 6/8 [00:03<00:01,  1.57ba/s]#015100%|██████████| 8/8 [00:04<00:00,  1.64ba/s]#015100%|██████████| 8/8 [00:04<00:00,  1.62ba/s]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/32 [00:00<?, ?ba/s]#015 75%|███████▌  | 6/8 [00:03<00:01,  1.53ba/s]#015 88%|████████▊ | 7/8 [00:04<00:00,  1.57ba/s]#015 88%|████████▊ | 7/8 [00:04<00:00,  1.57ba/s]#015 88%|████████▊ | 7/8 [00:04<00:00,  1.52ba/s]#015100%|██████████| 8/8 [00:05<00:00,  1.57ba/s]#015100%|██████████| 8/8 [00:05<00:00,  1.57ba/s]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 8/8 [00:05<00:00,  1.58ba/s]#015100%|██████████| 8/8 [00:05<00:00,  1.57ba/s]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/32 [00:00<?, ?ba/s]#015  0%|          | 0/32 [00:00<?, ?ba/s]#015  3%|▎         | 1/32 [00:01<00:35,  1.14s/ba]#015100%|██████████| 8/8 [00:05<00:00,  1.54ba/s]#015100%|██████████| 8/8 [00:05<00:00,  1.54ba/s]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/32 [00:00<?, ?ba/s]#015  3%|▎         | 1/32 [00:01<00:35,  1.15s/ba]#015  3%|▎         | 1/32 [00:01<00:36,  1.18s/ba]#015  6%|▋         | 2/32 [00:02<00:34,  1.15s/ba]#015  3%|▎         | 1/32 [00:01<00:36,  1.16s/ba]#015  6%|▋         | 2/32 [00:02<00:34,  1.16s/ba]#015  6%|▋         | 2/32 [00:02<00:35,  1.18s/ba]#015  9%|▉         | 3/32 [00:03<00:33,  1.15s/ba]#015  6%|▋         | 2/32 [00:02<00:35,  1.17s/ba]#015  9%|▉         | 3/32 [00:03<00:33,  1.16s/ba]#015  9%|▉         | 3/32 [00:03<00:34,  1.18s/ba]#015 12%|█▎        | 4/32 [00:04<00:32,  1.16s/ba]#015  9%|▉         | 3/32 [00:03<00:33,  1.17s/ba]#015 12%|█▎        | 4/32 [00:04<00:32,  1.16s/ba]#015 12%|█▎        | 4/32 [00:04<00:33,  1.18s/ba]#015 16%|█▌        | 5/32 [00:05<00:31,  1.16s/ba]#015 12%|█▎        | 4/32 [00:04<00:32,  1.18s/ba]#015 16%|█▌        | 5/32 [00:05<00:31,  1.16s/ba]#015 16%|█▌        | 5/32 [00:05<00:31,  1.18s/ba]#015 19%|█▉        | 6/32 [00:06<00:30,  1.16s/ba]#015 16%|█▌        | 5/32 [00:05<00:31,  1.18s/ba]#015 19%|█▉        | 6/32 [00:06<00:30,  1.16s/ba]#015 19%|█▉        | 6/32 [00:07<00:30,  1.18s/ba]#015 22%|██▏       | 7/32 [00:08<00:29,  1.16s/ba]#015 19%|█▉        | 6/32 [00:07<00:30,  1.18s/ba]#015 22%|██▏       | 7/32 [00:08<00:28,  1.16s/ba]#015 22%|██▏       | 7/32 [00:08<00:29,  1.18s/ba]#015 25%|██▌       | 8/32 [00:09<00:27,  1.16s/ba]#015 22%|██▏       | 7/32 [00:08<00:29,  1.18s/ba]#015 25%|██▌       | 8/32 [00:09<00:27,  1.16s/ba]#015 25%|██▌       | 8/32 [00:09<00:28,  1.18s/ba]#015 28%|██▊       | 9/32 [00:10<00:26,  1.16s/ba]#015 25%|██▌       | 8/32 [00:09<00:28,  1.18s/ba]#015 28%|██▊       | 9/32 [00:10<00:26,  1.16s/ba]#015 28%|██▊       | 9/32 [00:10<00:27,  1.18s/ba]#015 31%|███▏      | 10/32 [00:11<00:25,  1.17s/ba]#015 28%|██▊       | 9/32 [00:10<00:27,  1.18s/ba]#015 31%|███▏      | 10/32 [00:11<00:25,  1.16s/ba]#015 31%|███▏      | 10/32 [00:11<00:25,  1.18s/ba]#015 34%|███▍      | 11/32 [00:12<00:24,  1.17s/ba]#015 31%|███▏      | 10/32 [00:11<00:25,  1.18s/ba]#015 34%|███▍      | 11/32 [00:12<00:24,  1.17s/ba]#015 34%|███▍      | 11/32 [00:12<00:24,  1.18s/ba]#015 38%|███▊      | 12/32 [00:13<00:23,  1.16s/ba]#015 34%|███▍      | 11/32 [00:12<00:24,  1.18s/ba]#015 38%|███▊      | 12/32 [00:13<00:23,  1.16s/ba]#015 38%|███▊      | 12/32 [00:14<00:23,  1.18s/ba]#015 41%|████      | 13/32 [00:15<00:22,  1.17s/ba]#015 38%|███▊      | 12/32 [00:14<00:23,  1.17s/ba]#015 41%|████      | 13/32 [00:15<00:22,  1.16s/ba]#015 44%|████▍     | 14/32 [00:16<00:21,  1.17s/ba]#015 41%|████      | 13/32 [00:15<00:22,  1.18s/ba]#015 41%|████      | 13/32 [00:15<00:22,  1.18s/ba]#015 44%|████▍     | 14/32 [00:16<00:20,  1.16s/ba]#015 47%|████▋     | 15/32 [00:17<00:19,  1.16s/ba]#015 44%|████▍     | 14/32 [00:16<00:21,  1.18s/ba]#015 44%|████▍     | 14/32 [00:16<00:21,  1.18s/ba]#015 47%|████▋     | 15/32 [00:17<00:19,  1.17s/ba]#015 50%|█████     | 16/32 [00:18<00:18,  1.16s/ba]#015 47%|████▋     | 15/32 [00:17<00:20,  1.18s/ba]#015 47%|████▋     | 15/32 [00:17<00:19,  1.17s/ba]#015 50%|█████     | 16/32 [00:18<00:18,  1.16s/ba]#015 53%|█████▎    | 17/32 [00:19<00:17,  1.16s/ba]#015 50%|█████     | 16/32 [00:18<00:18,  1.18s/ba]#015 50%|█████     | 16/32 [00:18<00:18,  1.17s/ba]#015 53%|█████▎    | 17/32 [00:19<00:17,  1.16s/ba]#015 56%|█████▋    | 18/32 [00:20<00:16,  1.16s/ba]#015 53%|█████▎    | 17/32 [00:20<00:17,  1.18s/ba]#015 53%|█████▎    | 17/32 [00:19<00:17,  1.17s/ba]#015 56%|█████▋    | 18/32 [00:20<00:16,  1.16s/ba]#015 59%|█████▉    | 19/32 [00:22<00:15,  1.16s/ba]#015 56%|█████▋    | 18/32 [00:21<00:16,  1.18s/ba]#015 56%|█████▋    | 18/32 [00:21<00:16,  1.17s/ba]#015 59%|█████▉    | 19/32 [00:22<00:15,  1.17s/ba]#015 62%|██████▎   | 20/32 [00:23<00:13,  1.16s/ba]#015 59%|█████▉    | 19/32 [00:22<00:15,  1.18s/ba]#015 59%|█████▉    | 19/32 [00:22<00:15,  1.17s/ba]#015 62%|██████▎   | 20/32 [00:23<00:13,  1.16s/ba]#015 66%|██████▌   | 21/32 [00:24<00:12,  1.16s/ba]#015 62%|██████▎   | 20/32 [00:23<00:14,  1.18s/ba]#015 62%|██████▎   | 20/32 [00:23<00:14,  1.17s/ba]#015 66%|██████▌   | 21/32 [00:24<00:12,  1.16s/ba]#015 69%|██████▉   | 22/32 [00:25<00:11,  1.16s/ba]#015 66%|██████▌   | 21/32 [00:24<00:13,  1.18s/ba]#015 66%|██████▌   | 21/32 [00:24<00:12,  1.17s/ba]#015 69%|██████▉   | 22/32 [00:25<00:11,  1.16s/ba]#015 72%|███████▏  | 23/32 [00:26<00:10,  1.16s/ba]#015 69%|██████▉   | 22/32 [00:25<00:11,  1.18s/ba]#015 69%|██████▉   | 22/32 [00:25<00:11,  1.17s/ba]#015 72%|███████▏  | 23/32 [00:26<00:10,  1.17s/ba]#015 75%|███████▌  | 24/32 [00:27<00:09,  1.16s/ba]#015 72%|███████▏  | 23/32 [00:27<00:10,  1.18s/ba]#015 72%|███████▏  | 23/32 [00:26<00:10,  1.17s/ba]#015 75%|███████▌  | 24/32 [00:27<00:09,  1.16s/ba]#015 78%|███████▊  | 25/32 [00:29<00:08,  1.16s/ba]#015 75%|███████▌  | 24/32 [00:28<00:09,  1.18s/ba]#015 75%|███████▌  | 24/32 [00:28<00:09,  1.17s/ba]#015 78%|███████▊  | 25/32 [00:29<00:08,  1.16s/ba]#015 81%|████████▏ | 26/32 [00:30<00:06,  1.16s/ba]#015 78%|███████▊  | 25/32 [00:29<00:08,  1.17s/ba]#015 78%|███████▊  | 25/32 [00:29<00:08,  1.17s/ba]#015 81%|████████▏ | 26/32 [00:30<00:06,  1.16s/ba]#015 84%|████████▍ | 27/32 [00:31<00:05,  1.16s/ba]#015 81%|████████▏ | 26/32 [00:30<00:07,  1.18s/ba]#015 81%|████████▏ | 26/32 [00:30<00:07,  1.17s/ba]#015 84%|████████▍ | 27/32 [00:31<00:05,  1.16s/ba]#015 88%|████████▊ | 28/32 [00:32<00:04,  1.16s/ba]#015 84%|████████▍ | 27/32 [00:31<00:05,  1.18s/ba]#015 84%|████████▍ | 27/32 [00:31<00:05,  1.17s/ba]#015 88%|████████▊ | 28/32 [00:32<00:04,  1.16s/ba]#015 91%|█████████ | 29/32 [00:33<00:03,  1.16s/ba]#015 88%|████████▊ | 28/32 [00:33<00:04,  1.17s/ba]#015 88%|████████▊ | 28/32 [00:32<00:04,  1.17s/ba]#015 91%|█████████ | 29/32 [00:33<00:03,  1.16s/ba]#015 94%|█████████▍| 30/32 [00:34<00:02,  1.15s/ba]#015 91%|█████████ | 29/32 [00:34<00:03,  1.17s/ba]#015 91%|█████████ | 29/32 [00:34<00:03,  1.17s/ba]#015 94%|█████████▍| 30/32 [00:34<00:02,  1.16s/ba]#015 97%|█████████▋| 31/32 [00:35<00:01,  1.15s/ba]#015 94%|█████████▍| 30/32 [00:35<00:02,  1.18s/ba]#015 94%|█████████▍| 30/32 [00:35<00:02,  1.17s/ba]#015 97%|█████████▋| 31/32 [00:36<00:01,  1.16s/ba]#015100%|██████████| 32/32 [00:36<00:00,  1.10s/ba]#015100%|██████████| 32/32 [00:36<00:00,  1.15s/ba]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/8 [00:00<?, ?ba/s]#015 97%|█████████▋| 31/32 [00:36<00:01,  1.18s/ba]#015 97%|█████████▋| 31/32 [00:36<00:01,  1.17s/ba]#015100%|██████████| 32/32 [00:37<00:00,  1.11s/ba]#015100%|██████████| 32/32 [00:37<00:00,  1.16s/ba]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/8 [00:00<?, ?ba/s]#015 12%|█▎        | 1/8 [00:01<00:08,  1.15s/ba]#015100%|██████████| 32/32 [00:37<00:00,  1.13s/ba]#015100%|██████████| 32/32 [00:37<00:00,  1.17s/ba]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/8 [00:00<?, ?ba/s]#015100%|██████████| 32/32 [00:37<00:00,  1.12s/ba]#015100%|██████████| 32/32 [00:37<00:00,  1.17s/ba]\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/8 [00:00<?, ?ba/s]#015 12%|█▎        | 1/8 [00:01<00:07,  1.14s/ba]#015 25%|██▌       | 2/8 [00:02<00:06,  1.15s/ba]#015 12%|█▎        | 1/8 [00:01<00:08,  1.15s/ba]#015 12%|█▎        | 1/8 [00:01<00:08,  1.15s/ba]#015 25%|██▌       | 2/8 [00:02<00:06,  1.15s/ba]#015 38%|███▊      | 3/8 [00:03<00:05,  1.15s/ba]#015 25%|██▌       | 2/8 [00:02<00:07,  1.18s/ba]#015 25%|██▌       | 2/8 [00:02<00:06,  1.16s/ba]#015 38%|███▊      | 3/8 [00:03<00:05,  1.16s/ba]#015 50%|█████     | 4/8 [00:04<00:04,  1.15s/ba]#015 38%|███▊      | 3/8 [00:03<00:05,  1.18s/ba]#015 38%|███▊      | 3/8 [00:03<00:05,  1.16s/ba]#015 50%|█████     | 4/8 [00:04<00:04,  1.17s/ba]#015 62%|██████▎   | 5/8 [00:05<00:03,  1.15s/ba]#015 50%|█████     | 4/8 [00:04<00:04,  1.18s/ba]#015 50%|█████     | 4/8 [00:04<00:04,  1.17s/ba]#015 62%|██████▎   | 5/8 [00:05<00:03,  1.17s/ba]#015 75%|███████▌  | 6/8 [00:06<00:02,  1.15s/ba]#015 62%|██████▎   | 5/8 [00:05<00:03,  1.18s/ba]#015 62%|██████▎   | 5/8 [00:05<00:03,  1.17s/ba]#015 75%|███████▌  | 6/8 [00:06<00:02,  1.17s/ba]#015 88%|████████▊ | 7/8 [00:08<00:01,  1.16s/ba]#015 75%|███████▌  | 6/8 [00:07<00:02,  1.18s/ba]#015 75%|███████▌  | 6/8 [00:07<00:02,  1.17s/ba]#015 88%|████████▊ | 7/8 [00:08<00:01,  1.17s/ba]#015100%|██████████| 8/8 [00:09<00:00,  1.14s/ba]#015100%|██████████| 8/8 [00:09<00:00,  1.15s/ba]\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:09,821] [WARNING] [config_utils.py:67:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34m#015 88%|████████▊ | 7/8 [00:08<00:01,  1.18s/ba]#015 88%|████████▊ | 7/8 [00:08<00:01,  1.17s/ba]#015100%|██████████| 8/8 [00:09<00:00,  1.16s/ba]#015100%|██████████| 8/8 [00:09<00:00,  1.16s/ba]\u001b[0m\n",
      "\u001b[34m02/09/2023 06:44:10 - INFO - __main__ -   Grouping texts into single entries\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:565] 2023-02-09 06:44:10,904 >> Using cuda_amp half precision backend\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:10,907] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.7.7+2076bf23, git-hash=2076bf23, git-branch=HEAD\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:10,910] [WARNING] [config_utils.py:67:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 8/8 [00:09<00:00,  1.16s/ba]#015100%|██████████| 8/8 [00:09<00:00,  1.17s/ba]\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:11,554] [WARNING] [config_utils.py:67:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 8/8 [00:09<00:00,  1.15s/ba]#015100%|██████████| 8/8 [00:09<00:00,  1.16s/ba]\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:11,709] [WARNING] [config_utils.py:67:_process_deprecated_field] Config parameter stage3_gather_fp16_weights_on_model_save is deprecated use gather_16bit_weights_on_model_save instead\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:11,802] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:12,974] [WARNING] [cpu_adam.py:83:__init__] FP16 params for CPUAdam may not work on AMD CPUs\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:12,997] [WARNING] [cpu_adam.py:83:__init__] FP16 params for CPUAdam may not work on AMD CPUs\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:13,006] [WARNING] [cpu_adam.py:83:__init__] FP16 params for CPUAdam may not work on AMD CPUs\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:13,033] [WARNING] [cpu_adam.py:83:__init__] FP16 params for CPUAdam may not work on AMD CPUs\u001b[0m\n",
      "\u001b[34mAdam Optimizer #0 is created with AVX2 arithmetic capability.\u001b[0m\n",
      "\u001b[34mConfig: alpha=0.000005, betas=(0.900000, 0.999000), weight_decay=0.100000, adam_w=1\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:14,056] [INFO] [logging.py:68:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:14,072] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:14,072] [INFO] [utils.py:52:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:14,072] [INFO] [logging.py:68:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:14,152] [INFO] [utils.py:827:see_memory_usage] Stage 3 initialize beginning\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:14,153] [INFO] [utils.py:828:see_memory_usage] MA 0.88 GB         Max_MA 1.26 GB         CA 1.93 GB         Max_CA 2 GB \u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:14,153] [INFO] [utils.py:836:see_memory_usage] CPU Virtual Memory:  used = 28.96 GB, percent = 15.5%\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:14,155] [INFO] [stage3.py:114:__init__] Reduce bucket size 16777216\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:14,155] [INFO] [stage3.py:115:__init__] Prefetch bucket size 15099494\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:14,228] [INFO] [utils.py:827:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:14,229] [INFO] [utils.py:828:see_memory_usage] MA 0.88 GB         Max_MA 0.88 GB         CA 1.93 GB         Max_CA 2 GB \u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:14,229] [INFO] [utils.py:836:see_memory_usage] CPU Virtual Memory:  used = 29.27 GB, percent = 15.7%\u001b[0m\n",
      "\u001b[34mParameter Offload: Total persistent parameters: 811008 in 114 params\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:14,388] [INFO] [utils.py:827:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:14,388] [INFO] [utils.py:828:see_memory_usage] MA 0.11 GB         Max_MA 0.88 GB         CA 1.93 GB         Max_CA 2 GB \u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:14,389] [INFO] [utils.py:836:see_memory_usage] CPU Virtual Memory:  used = 29.46 GB, percent = 15.8%\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:25,083] [INFO] [stage3.py:369:_setup_for_real_optimizer] optimizer state initialized\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,233] [INFO] [utils.py:827:see_memory_usage] After initializing ZeRO optimizer\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,233] [INFO] [utils.py:828:see_memory_usage] MA 0.14 GB         Max_MA 0.91 GB         CA 1.93 GB         Max_CA 2 GB \u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,234] [INFO] [utils.py:836:see_memory_usage] CPU Virtual Memory:  used = 139.59 GB, percent = 74.8%\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,234] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,234] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupLR\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,234] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7fc53d6aeb50>\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,234] [INFO] [logging.py:68:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-06], mom=[[0.9, 0.999]]\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,235] [INFO] [config.py:1020:print] DeepSpeedEngine configuration:\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,235] [INFO] [config.py:1024:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,235] [INFO] [config.py:1024:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,235] [INFO] [config.py:1024:print]   amp_enabled .................. False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,235] [INFO] [config.py:1024:print]   amp_params ................... False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,235] [INFO] [config.py:1024:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,235] [INFO] [config.py:1024:print]   bfloat16_enabled ............. False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,235] [INFO] [config.py:1024:print]   checkpoint_parallel_write_pipeline  False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,235] [INFO] [config.py:1024:print]   checkpoint_tag_validation_enabled  True\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,235] [INFO] [config.py:1024:print]   checkpoint_tag_validation_fail  False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fc66bd323a0>\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   communication_data_type ...... None\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   curriculum_enabled ........... False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   curriculum_params ............ False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   dataloader_drop_last ......... False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   disable_allgather ............ False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   dump_state ................... False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   dynamic_loss_scale_args ...... {'init_scale': 4096, 'scale_window': 1000, 'delayed_shift': 2, 'min_scale': 1}\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   eigenvalue_enabled ........... False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   eigenvalue_gas_boundary_resolution  1\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   eigenvalue_layer_name ........ bert.encoder.layer\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   eigenvalue_layer_num ......... 0\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   eigenvalue_max_iter .......... 100\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   eigenvalue_stability ......... 1e-06\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   eigenvalue_tol ............... 0.01\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   eigenvalue_verbose ........... False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   elasticity_enabled ........... False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   fp16_auto_cast ............... False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   fp16_enabled ................. True\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   fp16_master_weights_and_gradients  False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   global_rank .................. 0\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   grad_accum_dtype ............. None\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   gradient_accumulation_steps .. 1\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   gradient_clipping ............ 1.0\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   gradient_predivide_factor .... 1.0\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   initial_dynamic_scale ........ 4096\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   load_universal_checkpoint .... False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   loss_scale ................... 0\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   memory_breakdown ............. False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,236] [INFO] [config.py:1024:print]   monitor_config ............... <deepspeed.monitor.config.DeepSpeedMonitorConfig object at 0x7fc66bd3b130>\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,237] [INFO] [config.py:1024:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,237] [INFO] [config.py:1024:print]   optimizer_legacy_fusion ...... False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,237] [INFO] [config.py:1024:print]   optimizer_name ............... adamw\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,237] [INFO] [config.py:1024:print]   optimizer_params ............. {'lr': 5e-06, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.1}\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,237] [INFO] [config.py:1024:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,237] [INFO] [config.py:1024:print]   pld_enabled .................. False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,237] [INFO] [config.py:1024:print]   pld_params ................... False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,237] [INFO] [config.py:1024:print]   prescale_gradients ........... False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,237] [INFO] [config.py:1024:print]   scheduler_name ............... WarmupLR\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,237] [INFO] [config.py:1024:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 5e-06, 'warmup_num_steps': 10}\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,237] [INFO] [config.py:1024:print]   sparse_attention ............. None\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,237] [INFO] [config.py:1024:print]   sparse_gradients_enabled ..... False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,237] [INFO] [config.py:1024:print]   steps_per_print .............. 2000\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,237] [INFO] [config.py:1024:print]   train_batch_size ............. 16\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,237] [INFO] [config.py:1024:print]   train_micro_batch_size_per_gpu  4\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,237] [INFO] [config.py:1024:print]   use_node_local_storage ....... False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,237] [INFO] [config.py:1024:print]   wall_clock_breakdown ......... False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,237] [INFO] [config.py:1024:print]   world_size ................... 4\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,237] [INFO] [config.py:1024:print]   zero_allow_untested_optimizer  False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,237] [INFO] [config.py:1024:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=16777216 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=15099494 param_persistence_threshold=40960 model_persistence_threshold=sys.maxsize max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,237] [INFO] [config.py:1024:print]   zero_enabled ................. True\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,237] [INFO] [config.py:1024:print]   zero_optimization_stage ...... 3\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:28,237] [INFO] [config.py:1009:print_user_config]   json = {\n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"loss_scale\": 0, \n",
      "        \"loss_scale_window\": 1000, \n",
      "        \"initial_scale_power\": 12, \n",
      "        \"hysteresis\": 2, \n",
      "        \"min_loss_scale\": 1\n",
      "    }, \n",
      "    \"bf16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"optimizer\": {\n",
      "        \"type\": \"AdamW\", \n",
      "        \"params\": {\n",
      "            \"lr\": 5e-06, \n",
      "            \"betas\": [0.9, 0.999], \n",
      "            \"eps\": 1e-08, \n",
      "            \"weight_decay\": 0.1\n",
      "        }\n",
      "    }, \n",
      "    \"scheduler\": {\n",
      "        \"type\": \"WarmupLR\", \n",
      "        \"params\": {\n",
      "            \"warmup_min_lr\": 0, \n",
      "            \"warmup_max_lr\": 5e-06, \n",
      "            \"warmup_num_steps\": 10\n",
      "        }\n",
      "    }, \u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1650] 2023-02-09 06:44:28,238 >> ***** Running training *****\n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 3, \n",
      "        \"offload_optimizer\": {\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1651] 2023-02-09 06:44:28,238 >>   Num examples = 31845\n",
      "            \"device\": \"cpu\", \u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1652] 2023-02-09 06:44:28,238 >>   Num Epochs = 12\n",
      "            \"pin_memory\": false\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": false\n",
      "        }, \n",
      "        \"overlap_comm\": true, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09, \n",
      "        \"reduce_bucket_size\": 1.677722e+07, \n",
      "        \"stage3_prefetch_bucket_size\": 1.509949e+07, \n",
      "        \"stage3_param_persistence_threshold\": 4.096000e+04, \n",
      "        \"stage3_max_live_parameters\": 1.000000e+09, \n",
      "        \"stage3_max_reuse_distance\": 1.000000e+09, \n",
      "        \"stage3_gather_fp16_weights_on_model_save\": true\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"gradient_clipping\": 1.0, \u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1653] 2023-02-09 06:44:28,238 >>   Instantaneous batch size per device = 4\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1654] 2023-02-09 06:44:28,238 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "    \"steps_per_print\": 2.000000e+03, \n",
      "    \"train_batch_size\": 16, \n",
      "    \"train_micro_batch_size_per_gpu\": 4, \n",
      "    \"wall_clock_breakdown\": false\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1655] 2023-02-09 06:44:28,238 >>   Gradient Accumulation steps = 1\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1656] 2023-02-09 06:44:28,238 >>   Total optimization steps = 23892\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1657] 2023-02-09 06:44:28,239 >>   Number of trainable parameters = 0\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/23892 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/distributed/distributed_c10d.py:2849: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/torch/distributed/distributed_c10d.py:2849: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/torch/distributed/distributed_c10d.py:2849: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/torch/distributed/distributed_c10d.py:2849: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:44:50,557] [INFO] [stage3.py:1816:_overflow_clean_up] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4096, reducing to 4096\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:45:09,379] [INFO] [stage3.py:1816:_overflow_clean_up] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4096, reducing to 2048.0\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:45:30,408] [INFO] [timer.py:197:stop] 0/3, RunningAvgSamplesPerSec=0.7614006387341624, CurrSamplesPerSec=0.7614006387341624, MemAllocated=0.14GB, MaxMemAllocated=8.91GB\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:45:51,106] [INFO] [timer.py:197:stop] 0/4, RunningAvgSamplesPerSec=0.7674352466550161, CurrSamplesPerSec=0.773566275360689, MemAllocated=0.14GB, MaxMemAllocated=8.91GB\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:46:12,019] [INFO] [timer.py:197:stop] 0/5, RunningAvgSamplesPerSec=0.766836400414718, CurrSamplesPerSec=0.765641507320939, MemAllocated=0.14GB, MaxMemAllocated=8.91GB\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:46:33,025] [INFO] [timer.py:197:stop] 0/6, RunningAvgSamplesPerSec=0.7656805533103741, CurrSamplesPerSec=0.7622338242890562, MemAllocated=0.14GB, MaxMemAllocated=8.91GB\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:46:53,903] [INFO] [timer.py:197:stop] 0/7, RunningAvgSamplesPerSec=0.765926159323108, CurrSamplesPerSec=0.766910161050546, MemAllocated=0.14GB, MaxMemAllocated=8.91GB\u001b[0m\n",
      "\u001b[34m[2023-02-09 06:47:14,654] [INFO] [timer.py:197:stop] 0/8, RunningAvgSamplesPerSec=0.7668682430197882, CurrSamplesPerSec=0.7716136393016212, MemAllocated=0.14GB, MaxMemAllocated=8.91GB\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.session import TrainingInput\n",
    "\n",
    "train_input = TrainingInput(\n",
    "    train_s3, content_type=\"csv\"\n",
    ")\n",
    "validation_input = TrainingInput(\n",
    "    val_s3, content_type=\"csv\"\n",
    ")\n",
    "\n",
    "sm_model.fit({\"train\": train_input, \"validation\": validation_input}, wait=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
